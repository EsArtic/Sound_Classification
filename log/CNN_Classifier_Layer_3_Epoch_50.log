Using TensorFlow backend.
fold1 raw_shape: (873, 128, 128) (873,) aug_shape: (853, 128, 128) (853,)
fold2 raw_shape: (888, 128, 128) (888,) aug_shape: (872, 128, 128) (872,)
fold3 raw_shape: (925, 128, 128) (925,) aug_shape: (892, 128, 128) (892,)
fold4 raw_shape: (990, 128, 128) (990,) aug_shape: (1007, 128, 128) (1007,)
fold5 raw_shape: (936, 128, 128) (936,) aug_shape: (963, 128, 128) (963,)
fold6 raw_shape: (823, 128, 128) (823,) aug_shape: (819, 128, 128) (819,)
fold7 raw_shape: (838, 128, 128) (838,) aug_shape: (882, 128, 128) (882,)
fold8 raw_shape: (806, 128, 128) (806,) aug_shape: (805, 128, 128) (805,)
fold9 raw_shape: (816, 128, 128) (816,) aug_shape: (837, 128, 128) (837,)
fold10 raw_shape: (837, 128, 128) (837,) aug_shape: (790, 128, 128) (790,)
tcmalloc: large alloc 2061238272 bytes == 0x86ae0000 @  0x7f4c6998b1e7 0x7f4c676c1a41 0x7f4c67724c13 0x7f4c677280c4 0x7f4c67728605 0x7f4c677bf201 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7f4c69588b97 0x5afa0a
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 15726 samples, validate on 873 samples
Epoch 1/50
2019-04-12 10:01:58.062624: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-04-12 10:01:58.065482: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1f5f1e0 executing computations on platform Host. Devices:
2019-04-12 10:01:58.065543: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-12 10:01:58.261326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-12 10:01:58.261901: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1f615a0 executing computations on platform CUDA. Devices:
2019-04-12 10:01:58.261939: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-04-12 10:01:58.262338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-04-12 10:01:58.262372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-04-12 10:01:59.781435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-12 10:01:59.781535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-04-12 10:01:59.781562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-04-12 10:01:59.784652: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2019-04-12 10:01:59.787166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
2019-04-12 10:02:00.446887: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
15726/15726 [==============================] - 14s 905us/step - loss: 2.1971 - acc: 0.1473 - val_loss: 2.0452 - val_acc: 0.1890
Epoch 2/50
15726/15726 [==============================] - 8s 510us/step - loss: 2.0205 - acc: 0.2197 - val_loss: 1.8432 - val_acc: 0.2635
Epoch 3/50
15726/15726 [==============================] - 8s 511us/step - loss: 1.8617 - acc: 0.2888 - val_loss: 1.6699 - val_acc: 0.2967
Epoch 4/50
15726/15726 [==============================] - 8s 508us/step - loss: 1.7336 - acc: 0.3448 - val_loss: 1.6110 - val_acc: 0.3792
Epoch 5/50
15726/15726 [==============================] - 8s 507us/step - loss: 1.6517 - acc: 0.3739 - val_loss: 1.6170 - val_acc: 0.4238
Epoch 6/50
15726/15726 [==============================] - 8s 509us/step - loss: 1.5499 - acc: 0.4175 - val_loss: 1.5197 - val_acc: 0.4605
Epoch 7/50
15726/15726 [==============================] - 8s 507us/step - loss: 1.4719 - acc: 0.4474 - val_loss: 1.4520 - val_acc: 0.4811
Epoch 8/50
15726/15726 [==============================] - 8s 508us/step - loss: 1.3744 - acc: 0.4919 - val_loss: 1.4750 - val_acc: 0.4788
Epoch 9/50
15726/15726 [==============================] - 8s 505us/step - loss: 1.3062 - acc: 0.5188 - val_loss: 1.3721 - val_acc: 0.5086
Epoch 10/50
15726/15726 [==============================] - 8s 507us/step - loss: 1.2521 - acc: 0.5408 - val_loss: 1.3276 - val_acc: 0.5086
Epoch 11/50
15726/15726 [==============================] - 8s 507us/step - loss: 1.2040 - acc: 0.5658 - val_loss: 1.3192 - val_acc: 0.5315
Epoch 12/50
15726/15726 [==============================] - 8s 514us/step - loss: 1.1443 - acc: 0.5890 - val_loss: 1.2436 - val_acc: 0.5853
Epoch 13/50
15726/15726 [==============================] - 8s 508us/step - loss: 1.1149 - acc: 0.6001 - val_loss: 1.2528 - val_acc: 0.6163
Epoch 14/50
15726/15726 [==============================] - 8s 512us/step - loss: 1.0797 - acc: 0.6165 - val_loss: 1.2458 - val_acc: 0.6014
Epoch 15/50
15726/15726 [==============================] - 8s 514us/step - loss: 1.0463 - acc: 0.6296 - val_loss: 1.2187 - val_acc: 0.6346
Epoch 16/50
15726/15726 [==============================] - 8s 511us/step - loss: 1.0131 - acc: 0.6445 - val_loss: 1.2583 - val_acc: 0.6506
Epoch 17/50
15726/15726 [==============================] - 8s 508us/step - loss: 0.9862 - acc: 0.6587 - val_loss: 1.2552 - val_acc: 0.5979
Epoch 18/50
15726/15726 [==============================] - 8s 506us/step - loss: 0.9588 - acc: 0.6628 - val_loss: 1.2412 - val_acc: 0.5956
Epoch 19/50
15726/15726 [==============================] - 8s 508us/step - loss: 0.9499 - acc: 0.6649 - val_loss: 1.1820 - val_acc: 0.6094
Epoch 20/50
15726/15726 [==============================] - 8s 508us/step - loss: 0.9158 - acc: 0.6805 - val_loss: 1.2541 - val_acc: 0.6632
Epoch 21/50
15726/15726 [==============================] - 8s 509us/step - loss: 0.8854 - acc: 0.6930 - val_loss: 1.1643 - val_acc: 0.6735
Epoch 22/50
15726/15726 [==============================] - 8s 511us/step - loss: 0.8583 - acc: 0.7011 - val_loss: 1.1052 - val_acc: 0.6884
Epoch 23/50
15726/15726 [==============================] - 8s 514us/step - loss: 0.8398 - acc: 0.7022 - val_loss: 1.2092 - val_acc: 0.6758
Epoch 24/50
15726/15726 [==============================] - 8s 514us/step - loss: 0.8146 - acc: 0.7180 - val_loss: 1.3123 - val_acc: 0.6506
Epoch 25/50
15726/15726 [==============================] - 8s 518us/step - loss: 0.8065 - acc: 0.7160 - val_loss: 1.2608 - val_acc: 0.6609
Epoch 26/50
15726/15726 [==============================] - 8s 516us/step - loss: 0.7844 - acc: 0.7265 - val_loss: 1.1645 - val_acc: 0.6678
Epoch 27/50
15726/15726 [==============================] - 8s 516us/step - loss: 0.7712 - acc: 0.7342 - val_loss: 1.2406 - val_acc: 0.6690
Epoch 28/50
15726/15726 [==============================] - 8s 513us/step - loss: 0.7535 - acc: 0.7353 - val_loss: 1.2754 - val_acc: 0.6712
Epoch 29/50
15726/15726 [==============================] - 8s 519us/step - loss: 0.7119 - acc: 0.7515 - val_loss: 1.0877 - val_acc: 0.6793
Epoch 30/50
15726/15726 [==============================] - 8s 516us/step - loss: 0.7162 - acc: 0.7542 - val_loss: 1.1067 - val_acc: 0.6816
Epoch 31/50
15726/15726 [==============================] - 8s 512us/step - loss: 0.6969 - acc: 0.7609 - val_loss: 1.2245 - val_acc: 0.6667
Epoch 32/50
15726/15726 [==============================] - 8s 517us/step - loss: 0.6866 - acc: 0.7620 - val_loss: 1.3045 - val_acc: 0.6667
Epoch 33/50
15726/15726 [==============================] - 8s 512us/step - loss: 0.6681 - acc: 0.7680 - val_loss: 1.1970 - val_acc: 0.6621
Epoch 34/50
15726/15726 [==============================] - 8s 512us/step - loss: 0.6841 - acc: 0.7609 - val_loss: 1.2418 - val_acc: 0.6621
Epoch 35/50
15726/15726 [==============================] - 8s 511us/step - loss: 0.6517 - acc: 0.7769 - val_loss: 1.3253 - val_acc: 0.6735
Epoch 36/50
15726/15726 [==============================] - 8s 511us/step - loss: 0.6414 - acc: 0.7806 - val_loss: 1.3859 - val_acc: 0.6506
Epoch 37/50
15726/15726 [==============================] - 8s 519us/step - loss: 0.6219 - acc: 0.7861 - val_loss: 1.3894 - val_acc: 0.6678
Epoch 38/50
15726/15726 [==============================] - 8s 518us/step - loss: 0.6167 - acc: 0.7899 - val_loss: 1.1831 - val_acc: 0.6758
Epoch 39/50
15726/15726 [==============================] - 8s 514us/step - loss: 0.6011 - acc: 0.7935 - val_loss: 1.4455 - val_acc: 0.6586
Epoch 40/50
15726/15726 [==============================] - 8s 512us/step - loss: 0.6270 - acc: 0.7844 - val_loss: 1.4008 - val_acc: 0.6586
Epoch 41/50
15726/15726 [==============================] - 8s 514us/step - loss: 0.5911 - acc: 0.7982 - val_loss: 1.3981 - val_acc: 0.6564
Epoch 42/50
15726/15726 [==============================] - 8s 515us/step - loss: 0.5910 - acc: 0.7960 - val_loss: 1.4957 - val_acc: 0.6690
Epoch 43/50
15726/15726 [==============================] - 8s 518us/step - loss: 0.5762 - acc: 0.8027 - val_loss: 1.4249 - val_acc: 0.6564
Epoch 44/50
15726/15726 [==============================] - 8s 515us/step - loss: 0.5567 - acc: 0.8104 - val_loss: 1.4566 - val_acc: 0.6770
Epoch 45/50
15726/15726 [==============================] - 8s 512us/step - loss: 0.5450 - acc: 0.8110 - val_loss: 1.4841 - val_acc: 0.6712
Epoch 46/50
15726/15726 [==============================] - 8s 510us/step - loss: 0.5200 - acc: 0.8200 - val_loss: 1.4590 - val_acc: 0.6873
Epoch 47/50
15726/15726 [==============================] - 8s 514us/step - loss: 0.5417 - acc: 0.8146 - val_loss: 1.4517 - val_acc: 0.6369
Epoch 48/50
15726/15726 [==============================] - 8s 512us/step - loss: 0.5437 - acc: 0.8134 - val_loss: 1.3023 - val_acc: 0.6816
Epoch 49/50
15726/15726 [==============================] - 8s 509us/step - loss: 0.5243 - acc: 0.8201 - val_loss: 1.3478 - val_acc: 0.6976
Epoch 50/50
15726/15726 [==============================] - 8s 511us/step - loss: 0.5343 - acc: 0.8163 - val_loss: 1.4451 - val_acc: 0.6827
873/873 [==============================] - 0s 336us/step
Cross Validation Fold 1
Test loss: 1.445089507374362
Test accuracy: 0.6827033218785796
tcmalloc: large alloc 2056781824 bytes == 0x86ae0000 @  0x7f4c6998b1e7 0x7f4c676c1a41 0x7f4c67724c13 0x7f4c677280c4 0x7f4c67728605 0x7f4c677bf201 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7f4c69588b97 0x5afa0a
Train on 15692 samples, validate on 888 samples
Epoch 1/50
15692/15692 [==============================] - 9s 573us/step - loss: 2.1579 - acc: 0.1672 - val_loss: 1.9296 - val_acc: 0.2410
Epoch 2/50
15692/15692 [==============================] - 8s 513us/step - loss: 1.8926 - acc: 0.2670 - val_loss: 1.8717 - val_acc: 0.3525
Epoch 3/50
15692/15692 [==============================] - 8s 516us/step - loss: 1.7049 - acc: 0.3460 - val_loss: 1.4532 - val_acc: 0.4291
Epoch 4/50
15692/15692 [==============================] - 8s 514us/step - loss: 1.5797 - acc: 0.4108 - val_loss: 1.3368 - val_acc: 0.4358
Epoch 5/50
15692/15692 [==============================] - 8s 513us/step - loss: 1.3999 - acc: 0.4894 - val_loss: 1.2927 - val_acc: 0.4628
Epoch 6/50
15692/15692 [==============================] - 8s 513us/step - loss: 1.2155 - acc: 0.5621 - val_loss: 1.1520 - val_acc: 0.5788
Epoch 7/50
15692/15692 [==============================] - 8s 512us/step - loss: 1.1361 - acc: 0.5965 - val_loss: 1.2323 - val_acc: 0.5664
Epoch 8/50
15692/15692 [==============================] - 8s 512us/step - loss: 1.0345 - acc: 0.6328 - val_loss: 1.1265 - val_acc: 0.5890
Epoch 9/50
15692/15692 [==============================] - 8s 511us/step - loss: 0.9450 - acc: 0.6672 - val_loss: 1.2103 - val_acc: 0.5642
Epoch 10/50
15692/15692 [==============================] - 8s 513us/step - loss: 0.8943 - acc: 0.6894 - val_loss: 1.1436 - val_acc: 0.5755
Epoch 11/50
15692/15692 [==============================] - 8s 509us/step - loss: 0.8435 - acc: 0.7017 - val_loss: 1.2285 - val_acc: 0.5462
Epoch 12/50
15692/15692 [==============================] - 8s 510us/step - loss: 0.7830 - acc: 0.7269 - val_loss: 1.2264 - val_acc: 0.5788
Epoch 13/50
15692/15692 [==============================] - 8s 510us/step - loss: 0.7253 - acc: 0.7494 - val_loss: 1.1616 - val_acc: 0.6081
Epoch 14/50
15692/15692 [==============================] - 8s 516us/step - loss: 0.7049 - acc: 0.7553 - val_loss: 1.2925 - val_acc: 0.5991
Epoch 15/50
15692/15692 [==============================] - 8s 510us/step - loss: 0.6591 - acc: 0.7702 - val_loss: 1.4575 - val_acc: 0.6284
Epoch 16/50
15692/15692 [==============================] - 8s 513us/step - loss: 0.6157 - acc: 0.7863 - val_loss: 1.3602 - val_acc: 0.6227
Epoch 17/50
15692/15692 [==============================] - 8s 513us/step - loss: 0.5698 - acc: 0.8058 - val_loss: 1.3847 - val_acc: 0.6385
Epoch 18/50
15692/15692 [==============================] - 8s 506us/step - loss: 0.5629 - acc: 0.8090 - val_loss: 1.6416 - val_acc: 0.6059
Epoch 19/50
15692/15692 [==============================] - 8s 518us/step - loss: 0.5232 - acc: 0.8211 - val_loss: 1.4154 - val_acc: 0.6419
Epoch 20/50
15692/15692 [==============================] - 8s 513us/step - loss: 0.5036 - acc: 0.8291 - val_loss: 1.5213 - val_acc: 0.6194
Epoch 21/50
15692/15692 [==============================] - 8s 515us/step - loss: 0.4847 - acc: 0.8356 - val_loss: 1.6781 - val_acc: 0.5957
Epoch 22/50
15692/15692 [==============================] - 8s 510us/step - loss: 0.4601 - acc: 0.8443 - val_loss: 1.6185 - val_acc: 0.6261
Epoch 23/50
15692/15692 [==============================] - 8s 511us/step - loss: 0.4445 - acc: 0.8504 - val_loss: 1.5381 - val_acc: 0.6351
Epoch 24/50
15692/15692 [==============================] - 8s 514us/step - loss: 0.4255 - acc: 0.8594 - val_loss: 1.6463 - val_acc: 0.6554
Epoch 25/50
15692/15692 [==============================] - 8s 511us/step - loss: 0.4214 - acc: 0.8597 - val_loss: 1.5964 - val_acc: 0.6340
Epoch 26/50
15692/15692 [==============================] - 8s 513us/step - loss: 0.3947 - acc: 0.8673 - val_loss: 1.7344 - val_acc: 0.6543
Epoch 27/50
15692/15692 [==============================] - 8s 513us/step - loss: 0.3942 - acc: 0.8653 - val_loss: 1.7679 - val_acc: 0.6408
Epoch 28/50
15692/15692 [==============================] - 8s 510us/step - loss: 0.3661 - acc: 0.8731 - val_loss: 1.5899 - val_acc: 0.6329
Epoch 29/50
15692/15692 [==============================] - 8s 510us/step - loss: 0.3479 - acc: 0.8822 - val_loss: 1.9835 - val_acc: 0.6295
Epoch 30/50
15692/15692 [==============================] - 8s 514us/step - loss: 0.3379 - acc: 0.8840 - val_loss: 1.6658 - val_acc: 0.6396
Epoch 31/50
15692/15692 [==============================] - 8s 514us/step - loss: 0.3351 - acc: 0.8873 - val_loss: 1.8333 - val_acc: 0.6306
Epoch 32/50
15692/15692 [==============================] - 8s 512us/step - loss: 0.3078 - acc: 0.8957 - val_loss: 1.8306 - val_acc: 0.6453
Epoch 33/50
15692/15692 [==============================] - 8s 514us/step - loss: 0.3307 - acc: 0.8905 - val_loss: 1.9311 - val_acc: 0.6396
Epoch 34/50
15692/15692 [==============================] - 8s 516us/step - loss: 0.3137 - acc: 0.8954 - val_loss: 1.7607 - val_acc: 0.6475
Epoch 35/50
15692/15692 [==============================] - 8s 516us/step - loss: 0.3024 - acc: 0.8982 - val_loss: 1.6321 - val_acc: 0.6464
Epoch 36/50
15692/15692 [==============================] - 8s 517us/step - loss: 0.3092 - acc: 0.8980 - val_loss: 1.6424 - val_acc: 0.6430
Epoch 37/50
15692/15692 [==============================] - 8s 511us/step - loss: 0.2932 - acc: 0.9019 - val_loss: 1.7886 - val_acc: 0.6678
Epoch 38/50
15692/15692 [==============================] - 8s 511us/step - loss: 0.2820 - acc: 0.9057 - val_loss: 2.3000 - val_acc: 0.6340
Epoch 39/50
15692/15692 [==============================] - 8s 513us/step - loss: 0.2686 - acc: 0.9100 - val_loss: 1.9080 - val_acc: 0.6599
Epoch 40/50
15692/15692 [==============================] - 8s 514us/step - loss: 0.2409 - acc: 0.9201 - val_loss: 2.1694 - val_acc: 0.6599
Epoch 41/50
15692/15692 [==============================] - 8s 515us/step - loss: 0.2564 - acc: 0.9137 - val_loss: 1.9631 - val_acc: 0.6689
Epoch 42/50
15692/15692 [==============================] - 8s 510us/step - loss: 0.2597 - acc: 0.9127 - val_loss: 2.1598 - val_acc: 0.6374
Epoch 43/50
15692/15692 [==============================] - 8s 513us/step - loss: 0.2466 - acc: 0.9180 - val_loss: 2.2873 - val_acc: 0.6453
Epoch 44/50
15692/15692 [==============================] - 8s 515us/step - loss: 0.2652 - acc: 0.9114 - val_loss: 1.6201 - val_acc: 0.6633
Epoch 45/50
15692/15692 [==============================] - 8s 512us/step - loss: 0.2248 - acc: 0.9238 - val_loss: 2.3289 - val_acc: 0.6565
Epoch 46/50
15692/15692 [==============================] - 8s 513us/step - loss: 0.2238 - acc: 0.9240 - val_loss: 2.1141 - val_acc: 0.6554
Epoch 47/50
15692/15692 [==============================] - 8s 510us/step - loss: 0.2147 - acc: 0.9254 - val_loss: 2.0115 - val_acc: 0.6622
Epoch 48/50
15692/15692 [==============================] - 8s 511us/step - loss: 0.2254 - acc: 0.9244 - val_loss: 1.8747 - val_acc: 0.6824
Epoch 49/50
15692/15692 [==============================] - 8s 511us/step - loss: 0.2118 - acc: 0.9294 - val_loss: 2.0485 - val_acc: 0.6520
Epoch 50/50
15692/15692 [==============================] - 8s 513us/step - loss: 0.2016 - acc: 0.9308 - val_loss: 2.2031 - val_acc: 0.6588
888/888 [==============================] - 0s 303us/step
Cross Validation Fold 2
Test loss: 2.2031426127865776
Test accuracy: 0.6587837837837838
tcmalloc: large alloc 2049310720 bytes == 0x86ae0000 @  0x7f4c6998b1e7 0x7f4c676c1a41 0x7f4c67724c13 0x7f4c677280c4 0x7f4c67728605 0x7f4c677bf201 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7f4c69588b97 0x5afa0a
Train on 15635 samples, validate on 925 samples
Epoch 1/50
15635/15635 [==============================] - 9s 569us/step - loss: 2.1667 - acc: 0.1641 - val_loss: 1.9838 - val_acc: 0.2562
Epoch 2/50
15635/15635 [==============================] - 8s 515us/step - loss: 1.9747 - acc: 0.2394 - val_loss: 1.9384 - val_acc: 0.2335
Epoch 3/50
15635/15635 [==============================] - 8s 519us/step - loss: 1.7857 - acc: 0.3072 - val_loss: 1.7508 - val_acc: 0.3405
Epoch 4/50
15635/15635 [==============================] - 8s 516us/step - loss: 1.6666 - acc: 0.3681 - val_loss: 1.7513 - val_acc: 0.3438
Epoch 5/50
15635/15635 [==============================] - 8s 512us/step - loss: 1.5479 - acc: 0.4164 - val_loss: 1.5737 - val_acc: 0.3503
Epoch 6/50
15635/15635 [==============================] - 8s 514us/step - loss: 1.4031 - acc: 0.4752 - val_loss: 1.5310 - val_acc: 0.5330
Epoch 7/50
15635/15635 [==============================] - 8s 514us/step - loss: 1.2972 - acc: 0.5180 - val_loss: 1.4259 - val_acc: 0.5135
Epoch 8/50
15635/15635 [==============================] - 8s 513us/step - loss: 1.2234 - acc: 0.5513 - val_loss: 1.4636 - val_acc: 0.4724
Epoch 9/50
15635/15635 [==============================] - 8s 511us/step - loss: 1.1482 - acc: 0.5822 - val_loss: 1.3494 - val_acc: 0.5243
Epoch 10/50
15635/15635 [==============================] - 8s 513us/step - loss: 1.0726 - acc: 0.6177 - val_loss: 1.3921 - val_acc: 0.5438
Epoch 11/50
15635/15635 [==============================] - 8s 515us/step - loss: 1.0025 - acc: 0.6439 - val_loss: 1.3696 - val_acc: 0.5286
Epoch 12/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.9561 - acc: 0.6614 - val_loss: 1.4550 - val_acc: 0.5265
Epoch 13/50
15635/15635 [==============================] - 8s 517us/step - loss: 0.9127 - acc: 0.6826 - val_loss: 1.3846 - val_acc: 0.5708
Epoch 14/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.8575 - acc: 0.6949 - val_loss: 1.4293 - val_acc: 0.5751
Epoch 15/50
15635/15635 [==============================] - 8s 518us/step - loss: 0.8175 - acc: 0.7192 - val_loss: 1.5509 - val_acc: 0.5568
Epoch 16/50
15635/15635 [==============================] - 8s 516us/step - loss: 0.7706 - acc: 0.7318 - val_loss: 1.4694 - val_acc: 0.6238
Epoch 17/50
15635/15635 [==============================] - 8s 513us/step - loss: 0.7298 - acc: 0.7457 - val_loss: 1.6202 - val_acc: 0.5676
Epoch 18/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.6928 - acc: 0.7643 - val_loss: 1.4248 - val_acc: 0.5773
Epoch 19/50
15635/15635 [==============================] - 8s 514us/step - loss: 0.6742 - acc: 0.7688 - val_loss: 1.3795 - val_acc: 0.6032
Epoch 20/50
15635/15635 [==============================] - 8s 513us/step - loss: 0.6450 - acc: 0.7778 - val_loss: 1.5344 - val_acc: 0.5978
Epoch 21/50
15635/15635 [==============================] - 8s 512us/step - loss: 0.6473 - acc: 0.7829 - val_loss: 1.4703 - val_acc: 0.5741
Epoch 22/50
15635/15635 [==============================] - 8s 517us/step - loss: 0.6217 - acc: 0.7873 - val_loss: 1.4242 - val_acc: 0.5773
Epoch 23/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.5853 - acc: 0.8010 - val_loss: 1.5144 - val_acc: 0.6108
Epoch 24/50
15635/15635 [==============================] - 8s 516us/step - loss: 0.5468 - acc: 0.8146 - val_loss: 1.4620 - val_acc: 0.6011
Epoch 25/50
15635/15635 [==============================] - 8s 516us/step - loss: 0.5190 - acc: 0.8236 - val_loss: 1.5304 - val_acc: 0.5968
Epoch 26/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.5124 - acc: 0.8257 - val_loss: 1.6140 - val_acc: 0.5665
Epoch 27/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.5207 - acc: 0.8266 - val_loss: 1.4345 - val_acc: 0.6270
Epoch 28/50
15635/15635 [==============================] - 8s 511us/step - loss: 0.4637 - acc: 0.8406 - val_loss: 1.7423 - val_acc: 0.6303
Epoch 29/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.4685 - acc: 0.8400 - val_loss: 1.7633 - val_acc: 0.5957
Epoch 30/50
15635/15635 [==============================] - 8s 516us/step - loss: 0.4546 - acc: 0.8460 - val_loss: 1.5284 - val_acc: 0.6270
Epoch 31/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.4206 - acc: 0.8571 - val_loss: 1.5570 - val_acc: 0.6389
Epoch 32/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.4164 - acc: 0.8597 - val_loss: 1.7559 - val_acc: 0.6130
Epoch 33/50
15635/15635 [==============================] - 8s 512us/step - loss: 0.4037 - acc: 0.8599 - val_loss: 1.7977 - val_acc: 0.6238
Epoch 34/50
15635/15635 [==============================] - 8s 516us/step - loss: 0.3992 - acc: 0.8618 - val_loss: 1.6733 - val_acc: 0.6141
Epoch 35/50
15635/15635 [==============================] - 8s 518us/step - loss: 0.3959 - acc: 0.8649 - val_loss: 1.7286 - val_acc: 0.5805
Epoch 36/50
15635/15635 [==============================] - 8s 516us/step - loss: 0.3857 - acc: 0.8675 - val_loss: 1.7867 - val_acc: 0.6422
Epoch 37/50
15635/15635 [==============================] - 8s 520us/step - loss: 0.3688 - acc: 0.8768 - val_loss: 1.8821 - val_acc: 0.6065
Epoch 38/50
15635/15635 [==============================] - 8s 517us/step - loss: 0.3708 - acc: 0.8763 - val_loss: 1.6117 - val_acc: 0.6324
Epoch 39/50
15635/15635 [==============================] - 8s 517us/step - loss: 0.3421 - acc: 0.8837 - val_loss: 1.9196 - val_acc: 0.6043
Epoch 40/50
15635/15635 [==============================] - 8s 517us/step - loss: 0.3407 - acc: 0.8827 - val_loss: 1.7005 - val_acc: 0.6086
Epoch 41/50
15635/15635 [==============================] - 8s 516us/step - loss: 0.3312 - acc: 0.8862 - val_loss: 1.7132 - val_acc: 0.6108
Epoch 42/50
15635/15635 [==============================] - 8s 519us/step - loss: 0.3216 - acc: 0.8899 - val_loss: 1.9716 - val_acc: 0.5989
Epoch 43/50
15635/15635 [==============================] - 8s 519us/step - loss: 0.3331 - acc: 0.8881 - val_loss: 1.9365 - val_acc: 0.5968
Epoch 44/50
15635/15635 [==============================] - 8s 516us/step - loss: 0.3028 - acc: 0.8973 - val_loss: 1.9290 - val_acc: 0.6281
Epoch 45/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.3094 - acc: 0.8972 - val_loss: 1.8624 - val_acc: 0.6151
Epoch 46/50
15635/15635 [==============================] - 8s 519us/step - loss: 0.3016 - acc: 0.8982 - val_loss: 2.0099 - val_acc: 0.6076
Epoch 47/50
15635/15635 [==============================] - 8s 518us/step - loss: 0.2913 - acc: 0.9016 - val_loss: 2.3036 - val_acc: 0.6032
Epoch 48/50
15635/15635 [==============================] - 8s 516us/step - loss: 0.2860 - acc: 0.8997 - val_loss: 1.9265 - val_acc: 0.6195
Epoch 49/50
15635/15635 [==============================] - 8s 515us/step - loss: 0.2869 - acc: 0.9019 - val_loss: 2.2758 - val_acc: 0.6151
Epoch 50/50
15635/15635 [==============================] - 8s 518us/step - loss: 0.2803 - acc: 0.9032 - val_loss: 2.0399 - val_acc: 0.6022
925/925 [==============================] - 0s 271us/step
Cross Validation Fold 3
Test loss: 2.0399411630469397
Test accuracy: 0.6021621618399748
tcmalloc: large alloc 2025717760 bytes == 0x86ae0000 @  0x7f4c6998b1e7 0x7f4c676c1a41 0x7f4c67724c13 0x7f4c677280c4 0x7f4c67728605 0x7f4c677bf201 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7f4c69588b97 0x5afa0a
Train on 15455 samples, validate on 990 samples
Epoch 1/50
15455/15455 [==============================] - 9s 598us/step - loss: 2.1744 - acc: 0.1526 - val_loss: 2.0954 - val_acc: 0.1677
Epoch 2/50
15455/15455 [==============================] - 8s 517us/step - loss: 1.9786 - acc: 0.2248 - val_loss: 1.9120 - val_acc: 0.2838
Epoch 3/50
15455/15455 [==============================] - 8s 517us/step - loss: 1.8403 - acc: 0.2798 - val_loss: 1.6694 - val_acc: 0.3525
Epoch 4/50
15455/15455 [==============================] - 8s 518us/step - loss: 1.6531 - acc: 0.3648 - val_loss: 1.4525 - val_acc: 0.4687
Epoch 5/50
15455/15455 [==============================] - 8s 513us/step - loss: 1.5214 - acc: 0.4341 - val_loss: 1.4481 - val_acc: 0.4677
Epoch 6/50
15455/15455 [==============================] - 8s 516us/step - loss: 1.4405 - acc: 0.4723 - val_loss: 1.3893 - val_acc: 0.5020
Epoch 7/50
15455/15455 [==============================] - 8s 525us/step - loss: 1.3276 - acc: 0.5196 - val_loss: 1.3449 - val_acc: 0.5545
Epoch 8/50
15455/15455 [==============================] - 8s 521us/step - loss: 1.2618 - acc: 0.5436 - val_loss: 1.2238 - val_acc: 0.5859
Epoch 9/50
15455/15455 [==============================] - 8s 518us/step - loss: 1.1540 - acc: 0.5841 - val_loss: 1.2034 - val_acc: 0.5879
Epoch 10/50
15455/15455 [==============================] - 8s 517us/step - loss: 1.0781 - acc: 0.6150 - val_loss: 1.2985 - val_acc: 0.5848
Epoch 11/50
15455/15455 [==============================] - 8s 512us/step - loss: 1.0156 - acc: 0.6310 - val_loss: 1.2018 - val_acc: 0.6101
Epoch 12/50
15455/15455 [==============================] - 8s 517us/step - loss: 0.9545 - acc: 0.6611 - val_loss: 1.2460 - val_acc: 0.6051
Epoch 13/50
15455/15455 [==============================] - 8s 514us/step - loss: 0.9168 - acc: 0.6738 - val_loss: 1.1756 - val_acc: 0.6182
Epoch 14/50
15455/15455 [==============================] - 8s 512us/step - loss: 0.8682 - acc: 0.6935 - val_loss: 1.1867 - val_acc: 0.6091
Epoch 15/50
15455/15455 [==============================] - 8s 513us/step - loss: 0.8135 - acc: 0.7147 - val_loss: 1.1453 - val_acc: 0.6202
Epoch 16/50
15455/15455 [==============================] - 8s 519us/step - loss: 0.7769 - acc: 0.7271 - val_loss: 1.2063 - val_acc: 0.6162
Epoch 17/50
15455/15455 [==============================] - 8s 510us/step - loss: 0.7439 - acc: 0.7386 - val_loss: 1.2165 - val_acc: 0.6212
Epoch 18/50
15455/15455 [==============================] - 8s 510us/step - loss: 0.7417 - acc: 0.7404 - val_loss: 1.2270 - val_acc: 0.6141
Epoch 19/50
15455/15455 [==============================] - 8s 512us/step - loss: 0.6834 - acc: 0.7570 - val_loss: 1.3557 - val_acc: 0.5768
Epoch 20/50
15455/15455 [==============================] - 8s 512us/step - loss: 0.6726 - acc: 0.7661 - val_loss: 1.2322 - val_acc: 0.6303
Epoch 21/50
15455/15455 [==============================] - 8s 515us/step - loss: 0.6222 - acc: 0.7858 - val_loss: 1.2267 - val_acc: 0.6333
Epoch 22/50
15455/15455 [==============================] - 8s 517us/step - loss: 0.5958 - acc: 0.7942 - val_loss: 1.2513 - val_acc: 0.6394
Epoch 23/50
15455/15455 [==============================] - 8s 518us/step - loss: 0.6094 - acc: 0.7909 - val_loss: 1.3245 - val_acc: 0.6101
Epoch 24/50
15455/15455 [==============================] - 8s 524us/step - loss: 0.6110 - acc: 0.7930 - val_loss: 1.4051 - val_acc: 0.5919
Epoch 25/50
15455/15455 [==============================] - 8s 516us/step - loss: 0.5610 - acc: 0.8023 - val_loss: 1.2813 - val_acc: 0.6485
Epoch 26/50
15455/15455 [==============================] - 8s 516us/step - loss: 0.5263 - acc: 0.8183 - val_loss: 1.3026 - val_acc: 0.6384
Epoch 27/50
15455/15455 [==============================] - 8s 516us/step - loss: 0.5276 - acc: 0.8193 - val_loss: 1.3547 - val_acc: 0.6333
Epoch 28/50
15455/15455 [==============================] - 8s 517us/step - loss: 0.5267 - acc: 0.8170 - val_loss: 1.2216 - val_acc: 0.6384
Epoch 29/50
15455/15455 [==============================] - 8s 525us/step - loss: 0.5022 - acc: 0.8289 - val_loss: 1.5007 - val_acc: 0.6253
Epoch 30/50
15455/15455 [==============================] - 8s 520us/step - loss: 0.4874 - acc: 0.8318 - val_loss: 1.4764 - val_acc: 0.6152
Epoch 31/50
15455/15455 [==============================] - 8s 517us/step - loss: 0.4741 - acc: 0.8399 - val_loss: 1.4219 - val_acc: 0.6343
Epoch 32/50
15455/15455 [==============================] - 8s 515us/step - loss: 0.4531 - acc: 0.8456 - val_loss: 1.3776 - val_acc: 0.6333
Epoch 33/50
15455/15455 [==============================] - 8s 521us/step - loss: 0.4569 - acc: 0.8423 - val_loss: 1.3825 - val_acc: 0.6313
Epoch 34/50
15455/15455 [==============================] - 8s 520us/step - loss: 0.4291 - acc: 0.8549 - val_loss: 1.4452 - val_acc: 0.6202
Epoch 35/50
15455/15455 [==============================] - 8s 521us/step - loss: 0.4243 - acc: 0.8528 - val_loss: 1.4892 - val_acc: 0.6323
Epoch 36/50
15455/15455 [==============================] - 8s 521us/step - loss: 0.4111 - acc: 0.8606 - val_loss: 1.5516 - val_acc: 0.6384
Epoch 37/50
15455/15455 [==============================] - 8s 524us/step - loss: 0.4373 - acc: 0.8522 - val_loss: 1.3869 - val_acc: 0.6394
Epoch 38/50
15455/15455 [==============================] - 8s 519us/step - loss: 0.3928 - acc: 0.8655 - val_loss: 1.4609 - val_acc: 0.6313
Epoch 39/50
15455/15455 [==============================] - 8s 519us/step - loss: 0.3922 - acc: 0.8666 - val_loss: 1.5169 - val_acc: 0.6434
Epoch 40/50
15455/15455 [==============================] - 8s 519us/step - loss: 0.3812 - acc: 0.8701 - val_loss: 1.5267 - val_acc: 0.6444
Epoch 41/50
15455/15455 [==============================] - 8s 520us/step - loss: 0.3682 - acc: 0.8728 - val_loss: 1.6773 - val_acc: 0.6030
Epoch 42/50
15455/15455 [==============================] - 8s 518us/step - loss: 0.3876 - acc: 0.8686 - val_loss: 1.5759 - val_acc: 0.6242
Epoch 43/50
15455/15455 [==============================] - 8s 518us/step - loss: 0.3720 - acc: 0.8729 - val_loss: 1.5099 - val_acc: 0.6485
Epoch 44/50
15455/15455 [==============================] - 8s 516us/step - loss: 0.3746 - acc: 0.8718 - val_loss: 1.6219 - val_acc: 0.6414
Epoch 45/50
15455/15455 [==============================] - 8s 523us/step - loss: 0.3710 - acc: 0.8729 - val_loss: 1.6338 - val_acc: 0.6293
Epoch 46/50
15455/15455 [==============================] - 8s 525us/step - loss: 0.3470 - acc: 0.8829 - val_loss: 1.5899 - val_acc: 0.6434
Epoch 47/50
15455/15455 [==============================] - 8s 527us/step - loss: 0.3309 - acc: 0.8863 - val_loss: 1.7681 - val_acc: 0.6111
Epoch 48/50
15455/15455 [==============================] - 8s 516us/step - loss: 0.3537 - acc: 0.8791 - val_loss: 1.6794 - val_acc: 0.6202
Epoch 49/50
15455/15455 [==============================] - 8s 517us/step - loss: 0.3308 - acc: 0.8859 - val_loss: 1.7758 - val_acc: 0.5919
Epoch 50/50
15455/15455 [==============================] - 8s 517us/step - loss: 0.3203 - acc: 0.8887 - val_loss: 1.6294 - val_acc: 0.6293
990/990 [==============================] - 0s 316us/step
Cross Validation Fold 4
Test loss: 1.6294247836777658
Test accuracy: 0.6292929286908622
tcmalloc: large alloc 2038562816 bytes == 0x7f4b767e0000 @  0x7f4c6998b1e7 0x7f4c676c1a41 0x7f4c67724c13 0x7f4c677280c4 0x7f4c67728605 0x7f4c677bf201 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7f4c69588b97 0x5afa0a
Train on 15553 samples, validate on 936 samples
Epoch 1/50
15553/15553 [==============================] - 9s 606us/step - loss: 2.1442 - acc: 0.1656 - val_loss: 2.0866 - val_acc: 0.2094
Epoch 2/50
15553/15553 [==============================] - 8s 522us/step - loss: 1.9434 - acc: 0.2409 - val_loss: 1.9894 - val_acc: 0.2265
Epoch 3/50
15553/15553 [==============================] - 8s 525us/step - loss: 1.8498 - acc: 0.2981 - val_loss: 1.9242 - val_acc: 0.2436
Epoch 4/50
15553/15553 [==============================] - 8s 526us/step - loss: 1.7367 - acc: 0.3449 - val_loss: 1.8421 - val_acc: 0.2660
Epoch 5/50
15553/15553 [==============================] - 8s 521us/step - loss: 1.6221 - acc: 0.3983 - val_loss: 1.6771 - val_acc: 0.3120
Epoch 6/50
15553/15553 [==============================] - 8s 519us/step - loss: 1.5076 - acc: 0.4452 - val_loss: 1.5212 - val_acc: 0.3643
Epoch 7/50
15553/15553 [==============================] - 8s 528us/step - loss: 1.3823 - acc: 0.4921 - val_loss: 1.3985 - val_acc: 0.4220
Epoch 8/50
15553/15553 [==============================] - 8s 524us/step - loss: 1.3002 - acc: 0.5290 - val_loss: 1.3613 - val_acc: 0.4519
Epoch 9/50
15553/15553 [==============================] - 8s 524us/step - loss: 1.2016 - acc: 0.5636 - val_loss: 1.2841 - val_acc: 0.5331
Epoch 10/50
15553/15553 [==============================] - 8s 524us/step - loss: 1.1488 - acc: 0.5881 - val_loss: 1.3141 - val_acc: 0.5128
Epoch 11/50
15553/15553 [==============================] - 8s 526us/step - loss: 1.0993 - acc: 0.6063 - val_loss: 1.2330 - val_acc: 0.5214
Epoch 12/50
15553/15553 [==============================] - 8s 523us/step - loss: 1.0438 - acc: 0.6238 - val_loss: 1.1294 - val_acc: 0.6175
Epoch 13/50
15553/15553 [==============================] - 8s 525us/step - loss: 1.0027 - acc: 0.6425 - val_loss: 1.2112 - val_acc: 0.5855
Epoch 14/50
15553/15553 [==============================] - 8s 524us/step - loss: 0.9439 - acc: 0.6648 - val_loss: 1.1425 - val_acc: 0.5962
Epoch 15/50
15553/15553 [==============================] - 8s 528us/step - loss: 0.8929 - acc: 0.6910 - val_loss: 1.0578 - val_acc: 0.6400
Epoch 16/50
15553/15553 [==============================] - 8s 529us/step - loss: 0.8462 - acc: 0.7062 - val_loss: 1.0542 - val_acc: 0.6335
Epoch 17/50
15553/15553 [==============================] - 8s 524us/step - loss: 0.7963 - acc: 0.7278 - val_loss: 1.0726 - val_acc: 0.6549
Epoch 18/50
15553/15553 [==============================] - 8s 524us/step - loss: 0.7605 - acc: 0.7343 - val_loss: 1.1168 - val_acc: 0.6335
Epoch 19/50
15553/15553 [==============================] - 8s 523us/step - loss: 0.7570 - acc: 0.7401 - val_loss: 1.1485 - val_acc: 0.6250
Epoch 20/50
15553/15553 [==============================] - 8s 519us/step - loss: 0.7214 - acc: 0.7494 - val_loss: 0.9717 - val_acc: 0.6538
Epoch 21/50
15553/15553 [==============================] - 8s 523us/step - loss: 0.6771 - acc: 0.7674 - val_loss: 1.1095 - val_acc: 0.6613
Epoch 22/50
15553/15553 [==============================] - 8s 523us/step - loss: 0.6569 - acc: 0.7687 - val_loss: 1.1116 - val_acc: 0.6688
Epoch 23/50
15553/15553 [==============================] - 8s 522us/step - loss: 0.6406 - acc: 0.7788 - val_loss: 1.0441 - val_acc: 0.6891
Epoch 24/50
15553/15553 [==============================] - 8s 523us/step - loss: 0.6171 - acc: 0.7885 - val_loss: 1.2628 - val_acc: 0.6400
Epoch 25/50
15553/15553 [==============================] - 8s 520us/step - loss: 0.6209 - acc: 0.7902 - val_loss: 1.0980 - val_acc: 0.6816
Epoch 26/50
15553/15553 [==============================] - 8s 520us/step - loss: 0.5699 - acc: 0.8060 - val_loss: 1.0662 - val_acc: 0.6699
Epoch 27/50
15553/15553 [==============================] - 8s 522us/step - loss: 0.5653 - acc: 0.8063 - val_loss: 1.1090 - val_acc: 0.6677
Epoch 28/50
15553/15553 [==============================] - 8s 530us/step - loss: 0.5559 - acc: 0.8103 - val_loss: 1.1074 - val_acc: 0.6880
Epoch 29/50
15553/15553 [==============================] - 8s 528us/step - loss: 0.5433 - acc: 0.8150 - val_loss: 1.1342 - val_acc: 0.6955
Epoch 30/50
15553/15553 [==============================] - 8s 519us/step - loss: 0.5125 - acc: 0.8247 - val_loss: 1.0947 - val_acc: 0.6891
Epoch 31/50
15553/15553 [==============================] - 8s 523us/step - loss: 0.4903 - acc: 0.8318 - val_loss: 1.1725 - val_acc: 0.6784
Epoch 32/50
15553/15553 [==============================] - 8s 520us/step - loss: 0.4822 - acc: 0.8346 - val_loss: 1.0943 - val_acc: 0.6571
Epoch 33/50
15553/15553 [==============================] - 8s 519us/step - loss: 0.4688 - acc: 0.8389 - val_loss: 1.2392 - val_acc: 0.6560
Epoch 34/50
15553/15553 [==============================] - 8s 519us/step - loss: 0.4497 - acc: 0.8476 - val_loss: 1.0317 - val_acc: 0.6859
Epoch 35/50
15553/15553 [==============================] - 8s 518us/step - loss: 0.4655 - acc: 0.8451 - val_loss: 1.0930 - val_acc: 0.6902
Epoch 36/50
15553/15553 [==============================] - 8s 519us/step - loss: 0.4351 - acc: 0.8519 - val_loss: 1.1139 - val_acc: 0.6966
Epoch 37/50
15553/15553 [==============================] - 8s 520us/step - loss: 0.4286 - acc: 0.8567 - val_loss: 0.9950 - val_acc: 0.7051
Epoch 38/50
15553/15553 [==============================] - 8s 522us/step - loss: 0.4123 - acc: 0.8603 - val_loss: 1.2255 - val_acc: 0.6741
Epoch 39/50
15553/15553 [==============================] - 8s 519us/step - loss: 0.4066 - acc: 0.8609 - val_loss: 1.0770 - val_acc: 0.7019
Epoch 40/50
15553/15553 [==============================] - 8s 520us/step - loss: 0.3853 - acc: 0.8682 - val_loss: 1.0144 - val_acc: 0.7105
Epoch 41/50
15553/15553 [==============================] - 8s 521us/step - loss: 0.3870 - acc: 0.8693 - val_loss: 0.9693 - val_acc: 0.6955
Epoch 42/50
15553/15553 [==============================] - 8s 521us/step - loss: 0.3757 - acc: 0.8720 - val_loss: 1.0862 - val_acc: 0.6859
Epoch 43/50
15553/15553 [==============================] - 8s 521us/step - loss: 0.3666 - acc: 0.8748 - val_loss: 1.0289 - val_acc: 0.7169
Epoch 44/50
15553/15553 [==============================] - 8s 515us/step - loss: 0.3552 - acc: 0.8814 - val_loss: 1.1212 - val_acc: 0.6987
Epoch 45/50
15553/15553 [==============================] - 8s 521us/step - loss: 0.3673 - acc: 0.8748 - val_loss: 0.9875 - val_acc: 0.7190
Epoch 46/50
15553/15553 [==============================] - 8s 521us/step - loss: 0.3632 - acc: 0.8754 - val_loss: 1.1458 - val_acc: 0.6976
Epoch 47/50
15553/15553 [==============================] - 8s 521us/step - loss: 0.3333 - acc: 0.8893 - val_loss: 1.0214 - val_acc: 0.7126
Epoch 48/50
15553/15553 [==============================] - 8s 522us/step - loss: 0.3314 - acc: 0.8879 - val_loss: 1.0639 - val_acc: 0.7201
Epoch 49/50
15553/15553 [==============================] - 8s 519us/step - loss: 0.3478 - acc: 0.8814 - val_loss: 1.0483 - val_acc: 0.7212
Epoch 50/50
15553/15553 [==============================] - 8s 523us/step - loss: 0.3165 - acc: 0.8933 - val_loss: 1.1612 - val_acc: 0.6955
936/936 [==============================] - 0s 306us/step
Cross Validation Fold 5
Test loss: 1.1612004360072634
Test accuracy: 0.6955128205128205
tcmalloc: large alloc 2072248320 bytes == 0x7f4afafa0000 @  0x7f4c6998b1e7 0x7f4c676c1a41 0x7f4c67724c13 0x7f4c677280c4 0x7f4c67728605 0x7f4c677bf201 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7f4c69588b97 0x5afa0a
Train on 15810 samples, validate on 823 samples
Epoch 1/50
15810/15810 [==============================] - 9s 599us/step - loss: 2.1344 - acc: 0.1773 - val_loss: 1.9268 - val_acc: 0.2576
Epoch 2/50
15810/15810 [==============================] - 8s 519us/step - loss: 1.9122 - acc: 0.2603 - val_loss: 1.8175 - val_acc: 0.3244
Epoch 3/50
15810/15810 [==============================] - 8s 515us/step - loss: 1.7536 - acc: 0.3363 - val_loss: 1.7200 - val_acc: 0.3463
Epoch 4/50
15810/15810 [==============================] - 8s 517us/step - loss: 1.5952 - acc: 0.4022 - val_loss: 1.5189 - val_acc: 0.4253
Epoch 5/50
15810/15810 [==============================] - 8s 517us/step - loss: 1.4211 - acc: 0.4783 - val_loss: 1.4651 - val_acc: 0.4471
Epoch 6/50
15810/15810 [==============================] - 8s 517us/step - loss: 1.3252 - acc: 0.5175 - val_loss: 1.4309 - val_acc: 0.4593
Epoch 7/50
15810/15810 [==============================] - 8s 518us/step - loss: 1.2052 - acc: 0.5682 - val_loss: 1.3764 - val_acc: 0.4751
Epoch 8/50
15810/15810 [==============================] - 8s 516us/step - loss: 1.1782 - acc: 0.5856 - val_loss: 1.2859 - val_acc: 0.5200
Epoch 9/50
15810/15810 [==============================] - 8s 516us/step - loss: 1.0913 - acc: 0.6185 - val_loss: 1.3006 - val_acc: 0.5091
Epoch 10/50
15810/15810 [==============================] - 8s 518us/step - loss: 1.0503 - acc: 0.6367 - val_loss: 1.3581 - val_acc: 0.4909
Epoch 11/50
15810/15810 [==============================] - 8s 519us/step - loss: 0.9727 - acc: 0.6621 - val_loss: 1.2432 - val_acc: 0.5322
Epoch 12/50
15810/15810 [==============================] - 8s 522us/step - loss: 0.9138 - acc: 0.6872 - val_loss: 1.2408 - val_acc: 0.5407
Epoch 13/50
15810/15810 [==============================] - 8s 515us/step - loss: 0.8948 - acc: 0.6909 - val_loss: 1.2474 - val_acc: 0.5371
Epoch 14/50
15810/15810 [==============================] - 8s 517us/step - loss: 0.8545 - acc: 0.7085 - val_loss: 1.3181 - val_acc: 0.5601
Epoch 15/50
15810/15810 [==============================] - 8s 517us/step - loss: 0.8274 - acc: 0.7163 - val_loss: 1.3765 - val_acc: 0.5492
Epoch 16/50
15810/15810 [==============================] - 8s 515us/step - loss: 0.8277 - acc: 0.7156 - val_loss: 1.3283 - val_acc: 0.5601
Epoch 17/50
15810/15810 [==============================] - 8s 512us/step - loss: 0.7390 - acc: 0.7456 - val_loss: 1.4889 - val_acc: 0.5492
Epoch 18/50
15810/15810 [==============================] - 8s 513us/step - loss: 0.7178 - acc: 0.7519 - val_loss: 1.3290 - val_acc: 0.5759
Epoch 19/50
15810/15810 [==============================] - 8s 516us/step - loss: 0.6856 - acc: 0.7660 - val_loss: 1.3001 - val_acc: 0.6002
Epoch 20/50
15810/15810 [==============================] - 8s 511us/step - loss: 0.6653 - acc: 0.7724 - val_loss: 1.3535 - val_acc: 0.5820
Epoch 21/50
15810/15810 [==============================] - 8s 517us/step - loss: 0.6446 - acc: 0.7809 - val_loss: 1.3982 - val_acc: 0.5930
Epoch 22/50
15810/15810 [==============================] - 8s 514us/step - loss: 0.6260 - acc: 0.7898 - val_loss: 1.2795 - val_acc: 0.6112
Epoch 23/50
15810/15810 [==============================] - 8s 514us/step - loss: 0.6228 - acc: 0.7870 - val_loss: 1.3094 - val_acc: 0.6075
Epoch 24/50
15810/15810 [==============================] - 8s 514us/step - loss: 0.5748 - acc: 0.8050 - val_loss: 1.4183 - val_acc: 0.6075
Epoch 25/50
15810/15810 [==============================] - 8s 517us/step - loss: 0.5724 - acc: 0.8039 - val_loss: 1.4609 - val_acc: 0.5796
Epoch 26/50
15810/15810 [==============================] - 8s 515us/step - loss: 0.5587 - acc: 0.8107 - val_loss: 1.3893 - val_acc: 0.6039
Epoch 27/50
15810/15810 [==============================] - 8s 511us/step - loss: 0.5434 - acc: 0.8133 - val_loss: 1.4129 - val_acc: 0.6112
Epoch 28/50
15810/15810 [==============================] - 8s 514us/step - loss: 0.5391 - acc: 0.8171 - val_loss: 1.3307 - val_acc: 0.6185
Epoch 29/50
15810/15810 [==============================] - 8s 518us/step - loss: 0.5164 - acc: 0.8262 - val_loss: 1.3095 - val_acc: 0.6367
Epoch 30/50
15810/15810 [==============================] - 8s 514us/step - loss: 0.5152 - acc: 0.8206 - val_loss: 1.6771 - val_acc: 0.6160
Epoch 31/50
15810/15810 [==============================] - 8s 514us/step - loss: 0.5019 - acc: 0.8262 - val_loss: 1.5421 - val_acc: 0.6112
Epoch 32/50
15810/15810 [==============================] - 8s 515us/step - loss: 0.5039 - acc: 0.8315 - val_loss: 1.5423 - val_acc: 0.6197
Epoch 33/50
15810/15810 [==============================] - 8s 515us/step - loss: 0.4773 - acc: 0.8391 - val_loss: 1.4107 - val_acc: 0.6282
Epoch 34/50
15810/15810 [==============================] - 8s 517us/step - loss: 0.4429 - acc: 0.8523 - val_loss: 1.4142 - val_acc: 0.6379
Epoch 35/50
15810/15810 [==============================] - 8s 515us/step - loss: 0.4364 - acc: 0.8483 - val_loss: 1.4977 - val_acc: 0.6185
Epoch 36/50
15810/15810 [==============================] - 8s 517us/step - loss: 0.4503 - acc: 0.8483 - val_loss: 1.4433 - val_acc: 0.6464
Epoch 37/50
15810/15810 [==============================] - 8s 515us/step - loss: 0.4182 - acc: 0.8572 - val_loss: 1.4285 - val_acc: 0.6513
Epoch 38/50
15810/15810 [==============================] - 8s 516us/step - loss: 0.4215 - acc: 0.8589 - val_loss: 1.3469 - val_acc: 0.6513
Epoch 39/50
15810/15810 [==============================] - 8s 517us/step - loss: 0.4078 - acc: 0.8614 - val_loss: 1.4470 - val_acc: 0.6476
Epoch 40/50
15810/15810 [==============================] - 8s 516us/step - loss: 0.3936 - acc: 0.8690 - val_loss: 1.5289 - val_acc: 0.6428
Epoch 41/50
15810/15810 [==============================] - 8s 516us/step - loss: 0.4105 - acc: 0.8612 - val_loss: 1.3346 - val_acc: 0.6586
Epoch 42/50
15810/15810 [==============================] - 8s 516us/step - loss: 0.3885 - acc: 0.8692 - val_loss: 1.5120 - val_acc: 0.6525
Epoch 43/50
15810/15810 [==============================] - 8s 517us/step - loss: 0.3703 - acc: 0.8736 - val_loss: 1.5662 - val_acc: 0.6440
Epoch 44/50
15810/15810 [==============================] - 8s 516us/step - loss: 0.3652 - acc: 0.8739 - val_loss: 1.7202 - val_acc: 0.6306
Epoch 45/50
15810/15810 [==============================] - 8s 516us/step - loss: 0.3797 - acc: 0.8705 - val_loss: 1.5570 - val_acc: 0.6233
Epoch 46/50
15810/15810 [==============================] - 8s 515us/step - loss: 0.3511 - acc: 0.8774 - val_loss: 1.5083 - val_acc: 0.6440
Epoch 47/50
15810/15810 [==============================] - 8s 511us/step - loss: 0.3631 - acc: 0.8779 - val_loss: 1.6014 - val_acc: 0.6513
Epoch 48/50
15810/15810 [==============================] - 8s 517us/step - loss: 0.3431 - acc: 0.8830 - val_loss: 1.4541 - val_acc: 0.6598
Epoch 49/50
15810/15810 [==============================] - 8s 524us/step - loss: 0.3277 - acc: 0.8874 - val_loss: 1.5540 - val_acc: 0.6610
Epoch 50/50
15810/15810 [==============================] - 8s 523us/step - loss: 0.3695 - acc: 0.8739 - val_loss: 1.4921 - val_acc: 0.6452
823/823 [==============================] - 0s 313us/step
Cross Validation Fold 6
Test loss: 1.4921079759609366
Test accuracy: 0.6452004853024952
Train on 15732 samples, validate on 838 samples
Epoch 1/50
15732/15732 [==============================] - 10s 617us/step - loss: 2.1688 - acc: 0.1476 - val_loss: 2.1362 - val_acc: 0.1611
Epoch 2/50
15732/15732 [==============================] - 8s 514us/step - loss: 2.0904 - acc: 0.1784 - val_loss: 2.0646 - val_acc: 0.2124
Epoch 3/50
15732/15732 [==============================] - 8s 516us/step - loss: 1.9422 - acc: 0.2461 - val_loss: 1.9404 - val_acc: 0.2375
Epoch 4/50
15732/15732 [==============================] - 8s 515us/step - loss: 1.8728 - acc: 0.2818 - val_loss: 1.8695 - val_acc: 0.3210
Epoch 5/50
15732/15732 [==============================] - 8s 516us/step - loss: 1.7676 - acc: 0.3389 - val_loss: 1.7841 - val_acc: 0.3484
Epoch 6/50
15732/15732 [==============================] - 8s 520us/step - loss: 1.6862 - acc: 0.3738 - val_loss: 1.7031 - val_acc: 0.3711
Epoch 7/50
15732/15732 [==============================] - 8s 520us/step - loss: 1.6047 - acc: 0.4013 - val_loss: 1.6372 - val_acc: 0.4248
Epoch 8/50
15732/15732 [==============================] - 8s 518us/step - loss: 1.5130 - acc: 0.4320 - val_loss: 1.5704 - val_acc: 0.4189
Epoch 9/50
15732/15732 [==============================] - 8s 514us/step - loss: 1.4676 - acc: 0.4540 - val_loss: 1.5409 - val_acc: 0.5394
Epoch 10/50
15732/15732 [==============================] - 8s 516us/step - loss: 1.3956 - acc: 0.4790 - val_loss: 1.4904 - val_acc: 0.4224
Epoch 11/50
15732/15732 [==============================] - 10s 621us/step - loss: 1.3367 - acc: 0.5025 - val_loss: 1.4871 - val_acc: 0.4010
Epoch 12/50
15732/15732 [==============================] - 8s 521us/step - loss: 1.3032 - acc: 0.5125 - val_loss: 1.4457 - val_acc: 0.4905
Epoch 13/50
15732/15732 [==============================] - 8s 523us/step - loss: 1.2280 - acc: 0.5452 - val_loss: 1.4667 - val_acc: 0.4379
Epoch 14/50
15732/15732 [==============================] - 8s 523us/step - loss: 1.1843 - acc: 0.5635 - val_loss: 1.3866 - val_acc: 0.4785
Epoch 15/50
15732/15732 [==============================] - 8s 520us/step - loss: 1.1402 - acc: 0.5781 - val_loss: 1.3828 - val_acc: 0.4749
Epoch 16/50
15732/15732 [==============================] - 8s 524us/step - loss: 1.1036 - acc: 0.5993 - val_loss: 1.4499 - val_acc: 0.4547
Epoch 17/50
15732/15732 [==============================] - 8s 521us/step - loss: 1.0448 - acc: 0.6245 - val_loss: 1.3071 - val_acc: 0.4952
Epoch 18/50
15732/15732 [==============================] - 8s 520us/step - loss: 1.0169 - acc: 0.6295 - val_loss: 1.3270 - val_acc: 0.5227
Epoch 19/50
15732/15732 [==============================] - 8s 526us/step - loss: 0.9694 - acc: 0.6564 - val_loss: 1.2587 - val_acc: 0.5442
Epoch 20/50
15732/15732 [==============================] - 8s 523us/step - loss: 0.9452 - acc: 0.6606 - val_loss: 1.3714 - val_acc: 0.5179
Epoch 21/50
15732/15732 [==============================] - 8s 523us/step - loss: 0.9060 - acc: 0.6705 - val_loss: 1.2598 - val_acc: 0.5764
Epoch 22/50
15732/15732 [==============================] - 8s 520us/step - loss: 0.8809 - acc: 0.6834 - val_loss: 1.3201 - val_acc: 0.4905
Epoch 23/50
15732/15732 [==============================] - 8s 519us/step - loss: 0.8678 - acc: 0.6873 - val_loss: 1.4062 - val_acc: 0.4558
Epoch 24/50
15732/15732 [==============================] - 8s 520us/step - loss: 0.8407 - acc: 0.6996 - val_loss: 1.2875 - val_acc: 0.5227
Epoch 25/50
15732/15732 [==============================] - 8s 521us/step - loss: 0.8245 - acc: 0.7027 - val_loss: 1.2318 - val_acc: 0.5382
Epoch 26/50
15732/15732 [==============================] - 8s 525us/step - loss: 0.7795 - acc: 0.7226 - val_loss: 1.1767 - val_acc: 0.6026
Epoch 27/50
15732/15732 [==============================] - 8s 522us/step - loss: 0.7753 - acc: 0.7287 - val_loss: 1.2139 - val_acc: 0.6050
Epoch 28/50
15732/15732 [==============================] - 8s 520us/step - loss: 0.7556 - acc: 0.7295 - val_loss: 1.1949 - val_acc: 0.5907
Epoch 29/50
15732/15732 [==============================] - 8s 520us/step - loss: 0.7118 - acc: 0.7476 - val_loss: 1.2289 - val_acc: 0.5955
Epoch 30/50
15732/15732 [==============================] - 8s 518us/step - loss: 0.7140 - acc: 0.7490 - val_loss: 1.3029 - val_acc: 0.6205
Epoch 31/50
15732/15732 [==============================] - 8s 519us/step - loss: 0.6889 - acc: 0.7618 - val_loss: 1.1277 - val_acc: 0.6229
Epoch 32/50
15732/15732 [==============================] - 8s 524us/step - loss: 0.6787 - acc: 0.7651 - val_loss: 1.2246 - val_acc: 0.6086
Epoch 33/50
15732/15732 [==============================] - 8s 520us/step - loss: 0.6597 - acc: 0.7677 - val_loss: 1.2138 - val_acc: 0.6241
Epoch 34/50
15732/15732 [==============================] - 8s 513us/step - loss: 0.6470 - acc: 0.7736 - val_loss: 1.2030 - val_acc: 0.6169
Epoch 35/50
15732/15732 [==============================] - 8s 515us/step - loss: 0.6244 - acc: 0.7810 - val_loss: 1.1345 - val_acc: 0.6456
Epoch 36/50
15732/15732 [==============================] - 8s 515us/step - loss: 0.6097 - acc: 0.7923 - val_loss: 1.2419 - val_acc: 0.6110
Epoch 37/50
15732/15732 [==============================] - 8s 511us/step - loss: 0.6106 - acc: 0.7894 - val_loss: 1.1482 - val_acc: 0.6432
Epoch 38/50
15732/15732 [==============================] - 8s 514us/step - loss: 0.5717 - acc: 0.7999 - val_loss: 1.1762 - val_acc: 0.6551
Epoch 39/50
15732/15732 [==============================] - 8s 513us/step - loss: 0.5602 - acc: 0.8073 - val_loss: 1.1409 - val_acc: 0.6718
Epoch 40/50
15732/15732 [==============================] - 8s 517us/step - loss: 0.5580 - acc: 0.8088 - val_loss: 1.1958 - val_acc: 0.6468
Epoch 41/50
15732/15732 [==============================] - 8s 514us/step - loss: 0.5362 - acc: 0.8122 - val_loss: 1.1110 - val_acc: 0.6480
Epoch 42/50
15732/15732 [==============================] - 8s 514us/step - loss: 0.5312 - acc: 0.8173 - val_loss: 1.1790 - val_acc: 0.6301
Epoch 43/50
15732/15732 [==============================] - 8s 514us/step - loss: 0.5312 - acc: 0.8179 - val_loss: 1.3538 - val_acc: 0.6074
Epoch 44/50
15732/15732 [==============================] - 8s 514us/step - loss: 0.5063 - acc: 0.8235 - val_loss: 1.2418 - val_acc: 0.6766
Epoch 45/50
15732/15732 [==============================] - 8s 516us/step - loss: 0.4923 - acc: 0.8291 - val_loss: 1.1910 - val_acc: 0.6563
Epoch 46/50
15732/15732 [==============================] - 8s 518us/step - loss: 0.4905 - acc: 0.8299 - val_loss: 1.1161 - val_acc: 0.6766
Epoch 47/50
15732/15732 [==============================] - 8s 512us/step - loss: 0.4730 - acc: 0.8379 - val_loss: 1.2313 - val_acc: 0.6384
Epoch 48/50
15732/15732 [==============================] - 8s 516us/step - loss: 0.4836 - acc: 0.8329 - val_loss: 1.1735 - val_acc: 0.6706
Epoch 49/50
15732/15732 [==============================] - 8s 516us/step - loss: 0.4647 - acc: 0.8406 - val_loss: 1.1494 - val_acc: 0.6850
Epoch 50/50
15732/15732 [==============================] - 8s 517us/step - loss: 0.4358 - acc: 0.8481 - val_loss: 1.2259 - val_acc: 0.6635
838/838 [==============================] - 0s 294us/step
Cross Validation Fold 7
Test loss: 1.2259309399953036
Test accuracy: 0.6634844869446356
Train on 15841 samples, validate on 806 samples
Epoch 1/50
15841/15841 [==============================] - 10s 615us/step - loss: 2.1940 - acc: 0.1485 - val_loss: 2.1194 - val_acc: 0.1588
Epoch 2/50
15841/15841 [==============================] - 8s 515us/step - loss: 2.1444 - acc: 0.1598 - val_loss: 2.0931 - val_acc: 0.1551
Epoch 3/50
15841/15841 [==============================] - 8s 516us/step - loss: 2.1082 - acc: 0.1744 - val_loss: 2.0149 - val_acc: 0.2295
Epoch 4/50
15841/15841 [==============================] - 8s 523us/step - loss: 1.9584 - acc: 0.2461 - val_loss: 1.6749 - val_acc: 0.3313
Epoch 5/50
15841/15841 [==============================] - 8s 524us/step - loss: 1.8619 - acc: 0.2931 - val_loss: 1.6626 - val_acc: 0.3734
Epoch 6/50
15841/15841 [==============================] - 8s 520us/step - loss: 1.7992 - acc: 0.3042 - val_loss: 1.6497 - val_acc: 0.3648
Epoch 7/50
15841/15841 [==============================] - 8s 520us/step - loss: 1.7628 - acc: 0.3180 - val_loss: 1.5178 - val_acc: 0.4429
Epoch 8/50
15841/15841 [==============================] - 8s 518us/step - loss: 1.6982 - acc: 0.3464 - val_loss: 1.5088 - val_acc: 0.4429
Epoch 9/50
15841/15841 [==============================] - 8s 518us/step - loss: 1.6079 - acc: 0.3908 - val_loss: 1.4322 - val_acc: 0.4764
Epoch 10/50
15841/15841 [==============================] - 8s 516us/step - loss: 1.5632 - acc: 0.4118 - val_loss: 1.3082 - val_acc: 0.5335
Epoch 11/50
15841/15841 [==============================] - 8s 518us/step - loss: 1.4027 - acc: 0.4829 - val_loss: 1.2580 - val_acc: 0.6042
Epoch 12/50
15841/15841 [==============================] - 8s 516us/step - loss: 1.3218 - acc: 0.5131 - val_loss: 1.2694 - val_acc: 0.6129
Epoch 13/50
15841/15841 [==============================] - 8s 514us/step - loss: 1.2439 - acc: 0.5464 - val_loss: 1.1843 - val_acc: 0.6725
Epoch 14/50
15841/15841 [==============================] - 8s 523us/step - loss: 1.1898 - acc: 0.5728 - val_loss: 1.1393 - val_acc: 0.6613
Epoch 15/50
15841/15841 [==============================] - 8s 525us/step - loss: 1.1559 - acc: 0.5870 - val_loss: 1.0975 - val_acc: 0.6911
Epoch 16/50
15841/15841 [==============================] - 8s 521us/step - loss: 1.1074 - acc: 0.6000 - val_loss: 1.1155 - val_acc: 0.6774
Epoch 17/50
15841/15841 [==============================] - 8s 513us/step - loss: 1.0727 - acc: 0.6130 - val_loss: 1.0991 - val_acc: 0.6700
Epoch 18/50
15841/15841 [==============================] - 8s 516us/step - loss: 1.0274 - acc: 0.6282 - val_loss: 1.1216 - val_acc: 0.6315
Epoch 19/50
15841/15841 [==============================] - 8s 512us/step - loss: 0.9969 - acc: 0.6400 - val_loss: 1.0594 - val_acc: 0.6998
Epoch 20/50
15841/15841 [==============================] - 8s 514us/step - loss: 0.9712 - acc: 0.6523 - val_loss: 1.0127 - val_acc: 0.7072
Epoch 21/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.9226 - acc: 0.6695 - val_loss: 1.0424 - val_acc: 0.7010
Epoch 22/50
15841/15841 [==============================] - 8s 515us/step - loss: 0.8887 - acc: 0.6802 - val_loss: 0.9876 - val_acc: 0.7134
Epoch 23/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.8766 - acc: 0.6933 - val_loss: 1.1154 - val_acc: 0.6973
Epoch 24/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.8414 - acc: 0.7040 - val_loss: 1.0750 - val_acc: 0.6873
Epoch 25/50
15841/15841 [==============================] - 8s 514us/step - loss: 0.8260 - acc: 0.7073 - val_loss: 1.0083 - val_acc: 0.7122
Epoch 26/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.7945 - acc: 0.7193 - val_loss: 0.9822 - val_acc: 0.7221
Epoch 27/50
15841/15841 [==============================] - 8s 515us/step - loss: 0.7805 - acc: 0.7286 - val_loss: 1.1156 - val_acc: 0.6650
Epoch 28/50
15841/15841 [==============================] - 8s 519us/step - loss: 0.7701 - acc: 0.7311 - val_loss: 0.9649 - val_acc: 0.7134
Epoch 29/50
15841/15841 [==============================] - 8s 514us/step - loss: 0.7278 - acc: 0.7445 - val_loss: 0.9914 - val_acc: 0.7270
Epoch 30/50
15841/15841 [==============================] - 8s 511us/step - loss: 0.7225 - acc: 0.7453 - val_loss: 1.0127 - val_acc: 0.7084
Epoch 31/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.7109 - acc: 0.7518 - val_loss: 1.1026 - val_acc: 0.6663
Epoch 32/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.6898 - acc: 0.7588 - val_loss: 1.0122 - val_acc: 0.7047
Epoch 33/50
15841/15841 [==============================] - 8s 515us/step - loss: 0.6884 - acc: 0.7614 - val_loss: 1.1611 - val_acc: 0.6551
Epoch 34/50
15841/15841 [==============================] - 8s 515us/step - loss: 0.6712 - acc: 0.7683 - val_loss: 1.0312 - val_acc: 0.7047
Epoch 35/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.6932 - acc: 0.7610 - val_loss: 1.0386 - val_acc: 0.7072
Epoch 36/50
15841/15841 [==============================] - 8s 519us/step - loss: 0.6290 - acc: 0.7833 - val_loss: 1.1101 - val_acc: 0.7047
Epoch 37/50
15841/15841 [==============================] - 8s 515us/step - loss: 0.6292 - acc: 0.7795 - val_loss: 1.0393 - val_acc: 0.7122
Epoch 38/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.6199 - acc: 0.7904 - val_loss: 1.0862 - val_acc: 0.7060
Epoch 39/50
15841/15841 [==============================] - 8s 515us/step - loss: 0.6019 - acc: 0.7933 - val_loss: 1.1181 - val_acc: 0.7159
Epoch 40/50
15841/15841 [==============================] - 8s 517us/step - loss: 0.5829 - acc: 0.7977 - val_loss: 1.1208 - val_acc: 0.7184
Epoch 41/50
15841/15841 [==============================] - 8s 517us/step - loss: 0.5900 - acc: 0.7945 - val_loss: 1.1585 - val_acc: 0.7022
Epoch 42/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.5955 - acc: 0.7926 - val_loss: 1.1874 - val_acc: 0.7084
Epoch 43/50
15841/15841 [==============================] - 8s 518us/step - loss: 0.5696 - acc: 0.8059 - val_loss: 1.1448 - val_acc: 0.6948
Epoch 44/50
15841/15841 [==============================] - 8s 518us/step - loss: 0.5633 - acc: 0.8049 - val_loss: 1.2371 - val_acc: 0.6898
Epoch 45/50
15841/15841 [==============================] - 8s 518us/step - loss: 0.5603 - acc: 0.8097 - val_loss: 1.2061 - val_acc: 0.7171
Epoch 46/50
15841/15841 [==============================] - 8s 517us/step - loss: 0.5423 - acc: 0.8140 - val_loss: 1.1788 - val_acc: 0.7184
Epoch 47/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.5297 - acc: 0.8181 - val_loss: 1.1478 - val_acc: 0.7134
Epoch 48/50
15841/15841 [==============================] - 8s 516us/step - loss: 0.5189 - acc: 0.8255 - val_loss: 1.1955 - val_acc: 0.7134
Epoch 49/50
15841/15841 [==============================] - 8s 517us/step - loss: 0.5128 - acc: 0.8202 - val_loss: 1.1714 - val_acc: 0.7084
Epoch 50/50
15841/15841 [==============================] - 8s 517us/step - loss: 0.5147 - acc: 0.8217 - val_loss: 1.1523 - val_acc: 0.6873
806/806 [==============================] - 0s 287us/step
Cross Validation Fold 8
Test loss: 1.1522982349762554
Test accuracy: 0.6873449131513648
Train on 15799 samples, validate on 816 samples
Epoch 1/50
15799/15799 [==============================] - 10s 618us/step - loss: 2.1955 - acc: 0.1498 - val_loss: 2.1071 - val_acc: 0.1275
Epoch 2/50
15799/15799 [==============================] - 8s 519us/step - loss: 2.0090 - acc: 0.2204 - val_loss: 1.8055 - val_acc: 0.2745
Epoch 3/50
15799/15799 [==============================] - 8s 523us/step - loss: 1.8004 - acc: 0.3135 - val_loss: 1.5715 - val_acc: 0.4289
Epoch 4/50
15799/15799 [==============================] - 8s 523us/step - loss: 1.5934 - acc: 0.4064 - val_loss: 1.4348 - val_acc: 0.4498
Epoch 5/50
15799/15799 [==============================] - 8s 522us/step - loss: 1.4411 - acc: 0.4723 - val_loss: 1.2972 - val_acc: 0.4914
Epoch 6/50
15799/15799 [==============================] - 8s 526us/step - loss: 1.3354 - acc: 0.5148 - val_loss: 1.3798 - val_acc: 0.4547
Epoch 7/50
15799/15799 [==============================] - 8s 524us/step - loss: 1.2744 - acc: 0.5428 - val_loss: 1.1878 - val_acc: 0.5748
Epoch 8/50
15799/15799 [==============================] - 8s 521us/step - loss: 1.1917 - acc: 0.5773 - val_loss: 1.1211 - val_acc: 0.6066
Epoch 9/50
15799/15799 [==============================] - 8s 524us/step - loss: 1.1174 - acc: 0.6013 - val_loss: 1.1327 - val_acc: 0.5919
Epoch 10/50
15799/15799 [==============================] - 8s 525us/step - loss: 1.0554 - acc: 0.6267 - val_loss: 1.0734 - val_acc: 0.6029
Epoch 11/50
15799/15799 [==============================] - 8s 519us/step - loss: 1.0091 - acc: 0.6536 - val_loss: 1.0352 - val_acc: 0.6299
Epoch 12/50
15799/15799 [==============================] - 8s 521us/step - loss: 0.9610 - acc: 0.6656 - val_loss: 1.1235 - val_acc: 0.6066
Epoch 13/50
15799/15799 [==============================] - 8s 524us/step - loss: 0.9232 - acc: 0.6846 - val_loss: 1.0468 - val_acc: 0.6275
Epoch 14/50
15799/15799 [==============================] - 8s 525us/step - loss: 0.8731 - acc: 0.7011 - val_loss: 0.9907 - val_acc: 0.6422
Epoch 15/50
15799/15799 [==============================] - 8s 525us/step - loss: 0.8333 - acc: 0.7182 - val_loss: 0.9841 - val_acc: 0.6422
Epoch 16/50
15799/15799 [==============================] - 8s 524us/step - loss: 0.8100 - acc: 0.7203 - val_loss: 1.0143 - val_acc: 0.6544
Epoch 17/50
15799/15799 [==============================] - 8s 523us/step - loss: 0.7760 - acc: 0.7345 - val_loss: 0.9752 - val_acc: 0.6703
Epoch 18/50
15799/15799 [==============================] - 8s 522us/step - loss: 0.7436 - acc: 0.7470 - val_loss: 0.9287 - val_acc: 0.6556
Epoch 19/50
15799/15799 [==============================] - 8s 525us/step - loss: 0.7529 - acc: 0.7413 - val_loss: 1.0150 - val_acc: 0.6532
Epoch 20/50
15799/15799 [==============================] - 8s 526us/step - loss: 0.6966 - acc: 0.7621 - val_loss: 0.9454 - val_acc: 0.6679
Epoch 21/50
15799/15799 [==============================] - 8s 521us/step - loss: 0.6786 - acc: 0.7752 - val_loss: 0.8716 - val_acc: 0.7034
Epoch 22/50
15799/15799 [==============================] - 8s 523us/step - loss: 0.6534 - acc: 0.7829 - val_loss: 1.0514 - val_acc: 0.6863
Epoch 23/50
15799/15799 [==============================] - 8s 526us/step - loss: 0.6326 - acc: 0.7857 - val_loss: 0.9047 - val_acc: 0.6838
Epoch 24/50
15799/15799 [==============================] - 8s 523us/step - loss: 0.6044 - acc: 0.7969 - val_loss: 0.9735 - val_acc: 0.6912
Epoch 25/50
15799/15799 [==============================] - 8s 525us/step - loss: 0.6009 - acc: 0.7949 - val_loss: 0.9239 - val_acc: 0.6838
Epoch 26/50
15799/15799 [==============================] - 8s 523us/step - loss: 0.5913 - acc: 0.8021 - val_loss: 0.7982 - val_acc: 0.7120
Epoch 27/50
15799/15799 [==============================] - 8s 522us/step - loss: 0.5608 - acc: 0.8130 - val_loss: 0.8932 - val_acc: 0.6740
Epoch 28/50
15799/15799 [==============================] - 8s 527us/step - loss: 0.5544 - acc: 0.8120 - val_loss: 0.8221 - val_acc: 0.7328
Epoch 29/50
15799/15799 [==============================] - 8s 523us/step - loss: 0.5347 - acc: 0.8215 - val_loss: 0.9603 - val_acc: 0.7132
Epoch 30/50
15799/15799 [==============================] - 8s 525us/step - loss: 0.5061 - acc: 0.8301 - val_loss: 0.8405 - val_acc: 0.7353
Epoch 31/50
15799/15799 [==============================] - 8s 522us/step - loss: 0.5059 - acc: 0.8270 - val_loss: 0.8731 - val_acc: 0.7034
Epoch 32/50
15799/15799 [==============================] - 8s 518us/step - loss: 0.5025 - acc: 0.8284 - val_loss: 0.9068 - val_acc: 0.7157
Epoch 33/50
15799/15799 [==============================] - 8s 522us/step - loss: 0.5262 - acc: 0.8223 - val_loss: 0.8708 - val_acc: 0.6973
Epoch 34/50
15799/15799 [==============================] - 8s 531us/step - loss: 0.4704 - acc: 0.8419 - val_loss: 0.8763 - val_acc: 0.7145
Epoch 35/50
15799/15799 [==============================] - 8s 535us/step - loss: 0.4530 - acc: 0.8489 - val_loss: 0.9457 - val_acc: 0.6752
Epoch 36/50
15799/15799 [==============================] - 8s 527us/step - loss: 0.4709 - acc: 0.8376 - val_loss: 0.9165 - val_acc: 0.7108
Epoch 37/50
15799/15799 [==============================] - 8s 521us/step - loss: 0.4405 - acc: 0.8498 - val_loss: 0.9377 - val_acc: 0.7169
Epoch 38/50
15799/15799 [==============================] - 8s 524us/step - loss: 0.4316 - acc: 0.8529 - val_loss: 1.0150 - val_acc: 0.7022
Epoch 39/50
15799/15799 [==============================] - 8s 519us/step - loss: 0.4206 - acc: 0.8576 - val_loss: 0.9655 - val_acc: 0.6985
Epoch 40/50
15799/15799 [==============================] - 8s 524us/step - loss: 0.4137 - acc: 0.8603 - val_loss: 1.1116 - val_acc: 0.6850
Epoch 41/50
15799/15799 [==============================] - 8s 522us/step - loss: 0.4335 - acc: 0.8533 - val_loss: 1.0085 - val_acc: 0.7034
Epoch 42/50
15799/15799 [==============================] - 8s 521us/step - loss: 0.3875 - acc: 0.8676 - val_loss: 0.9610 - val_acc: 0.7034
Epoch 43/50
15799/15799 [==============================] - 8s 525us/step - loss: 0.3889 - acc: 0.8689 - val_loss: 0.9613 - val_acc: 0.7206
Epoch 44/50
15799/15799 [==============================] - 8s 523us/step - loss: 0.3837 - acc: 0.8718 - val_loss: 0.9102 - val_acc: 0.7243
Epoch 45/50
15799/15799 [==============================] - 8s 523us/step - loss: 0.3636 - acc: 0.8788 - val_loss: 1.0006 - val_acc: 0.7132
Epoch 46/50
15799/15799 [==============================] - 8s 521us/step - loss: 0.3711 - acc: 0.8742 - val_loss: 0.9052 - val_acc: 0.7022
Epoch 47/50
15799/15799 [==============================] - 8s 526us/step - loss: 0.3647 - acc: 0.8766 - val_loss: 0.9391 - val_acc: 0.7488
Epoch 48/50
15799/15799 [==============================] - 8s 521us/step - loss: 0.3588 - acc: 0.8764 - val_loss: 1.0433 - val_acc: 0.7206
Epoch 49/50
15799/15799 [==============================] - 8s 519us/step - loss: 0.3392 - acc: 0.8808 - val_loss: 0.9720 - val_acc: 0.7316
Epoch 50/50
15799/15799 [==============================] - 8s 523us/step - loss: 0.3574 - acc: 0.8783 - val_loss: 0.9534 - val_acc: 0.7255
816/816 [==============================] - 0s 311us/step
Cross Validation Fold 9
Test loss: 0.9533992407971299
Test accuracy: 0.7254901960784313
Train on 15825 samples, validate on 837 samples
Epoch 1/50
15825/15825 [==============================] - 10s 633us/step - loss: 2.1799 - acc: 0.1552 - val_loss: 2.0177 - val_acc: 0.2091
Epoch 2/50
15825/15825 [==============================] - 8s 522us/step - loss: 1.9939 - acc: 0.2294 - val_loss: 1.8414 - val_acc: 0.2748
Epoch 3/50
15825/15825 [==============================] - 8s 521us/step - loss: 1.8758 - acc: 0.2764 - val_loss: 1.7778 - val_acc: 0.2593
Epoch 4/50
15825/15825 [==============================] - 8s 524us/step - loss: 1.7953 - acc: 0.3203 - val_loss: 1.6814 - val_acc: 0.4182
Epoch 5/50
15825/15825 [==============================] - 8s 523us/step - loss: 1.6741 - acc: 0.3669 - val_loss: 1.5579 - val_acc: 0.4409
Epoch 6/50
15825/15825 [==============================] - 8s 522us/step - loss: 1.5949 - acc: 0.3971 - val_loss: 1.4982 - val_acc: 0.4612
Epoch 7/50
15825/15825 [==============================] - 8s 522us/step - loss: 1.4663 - acc: 0.4555 - val_loss: 1.4411 - val_acc: 0.4767
Epoch 8/50
15825/15825 [==============================] - 8s 525us/step - loss: 1.4025 - acc: 0.4835 - val_loss: 1.3762 - val_acc: 0.5221
Epoch 9/50
15825/15825 [==============================] - 8s 524us/step - loss: 1.3212 - acc: 0.5183 - val_loss: 1.2936 - val_acc: 0.5173
Epoch 10/50
15825/15825 [==============================] - 8s 523us/step - loss: 1.2323 - acc: 0.5518 - val_loss: 1.2671 - val_acc: 0.5257
Epoch 11/50
15825/15825 [==============================] - 8s 524us/step - loss: 1.1872 - acc: 0.5705 - val_loss: 1.2002 - val_acc: 0.5508
Epoch 12/50
15825/15825 [==============================] - 8s 526us/step - loss: 1.1240 - acc: 0.5953 - val_loss: 1.1816 - val_acc: 0.5639
Epoch 13/50
15825/15825 [==============================] - 8s 522us/step - loss: 1.0856 - acc: 0.6145 - val_loss: 1.1238 - val_acc: 0.5806
Epoch 14/50
15825/15825 [==============================] - 8s 521us/step - loss: 1.0179 - acc: 0.6399 - val_loss: 1.1070 - val_acc: 0.5842
Epoch 15/50
15825/15825 [==============================] - 8s 520us/step - loss: 0.9717 - acc: 0.6533 - val_loss: 1.1046 - val_acc: 0.5747
Epoch 16/50
15825/15825 [==============================] - 8s 528us/step - loss: 0.8952 - acc: 0.6833 - val_loss: 1.0837 - val_acc: 0.5818
Epoch 17/50
15825/15825 [==============================] - 8s 530us/step - loss: 0.8927 - acc: 0.6813 - val_loss: 1.0553 - val_acc: 0.6284
Epoch 18/50
15825/15825 [==============================] - 8s 526us/step - loss: 0.8375 - acc: 0.7076 - val_loss: 1.0275 - val_acc: 0.6272
Epoch 19/50
15825/15825 [==============================] - 8s 522us/step - loss: 0.7913 - acc: 0.7284 - val_loss: 1.0386 - val_acc: 0.6344
Epoch 20/50
15825/15825 [==============================] - 8s 525us/step - loss: 0.7668 - acc: 0.7311 - val_loss: 0.9624 - val_acc: 0.6559
Epoch 21/50
15825/15825 [==============================] - 8s 520us/step - loss: 0.7336 - acc: 0.7445 - val_loss: 0.9404 - val_acc: 0.6499
Epoch 22/50
15825/15825 [==============================] - 8s 523us/step - loss: 0.7257 - acc: 0.7441 - val_loss: 0.9686 - val_acc: 0.6416
Epoch 23/50
15825/15825 [==============================] - 8s 521us/step - loss: 0.6885 - acc: 0.7603 - val_loss: 0.9770 - val_acc: 0.6714
Epoch 24/50
15825/15825 [==============================] - 8s 517us/step - loss: 0.6701 - acc: 0.7731 - val_loss: 1.0275 - val_acc: 0.6631
Epoch 25/50
15825/15825 [==============================] - 8s 521us/step - loss: 0.6605 - acc: 0.7675 - val_loss: 0.9568 - val_acc: 0.6655
Epoch 26/50
15825/15825 [==============================] - 8s 513us/step - loss: 0.6125 - acc: 0.7925 - val_loss: 0.9858 - val_acc: 0.6870
Epoch 27/50
15825/15825 [==============================] - 8s 524us/step - loss: 0.5946 - acc: 0.7915 - val_loss: 0.9930 - val_acc: 0.6774
Epoch 28/50
15825/15825 [==============================] - 8s 519us/step - loss: 0.5945 - acc: 0.7947 - val_loss: 1.0386 - val_acc: 0.6487
Epoch 29/50
15825/15825 [==============================] - 8s 516us/step - loss: 0.5582 - acc: 0.8068 - val_loss: 1.0094 - val_acc: 0.6906
Epoch 30/50
15825/15825 [==============================] - 8s 523us/step - loss: 0.5458 - acc: 0.8091 - val_loss: 1.0082 - val_acc: 0.6930
Epoch 31/50
15825/15825 [==============================] - 8s 517us/step - loss: 0.5298 - acc: 0.8171 - val_loss: 0.9886 - val_acc: 0.7109
Epoch 32/50
15825/15825 [==============================] - 8s 519us/step - loss: 0.5296 - acc: 0.8185 - val_loss: 1.0176 - val_acc: 0.6906
Epoch 33/50
15825/15825 [==============================] - 8s 520us/step - loss: 0.5133 - acc: 0.8255 - val_loss: 1.0493 - val_acc: 0.6965
Epoch 34/50
15825/15825 [==============================] - 8s 520us/step - loss: 0.4974 - acc: 0.8269 - val_loss: 0.9466 - val_acc: 0.6846
Epoch 35/50
15825/15825 [==============================] - 8s 519us/step - loss: 0.4909 - acc: 0.8324 - val_loss: 0.9743 - val_acc: 0.7264
Epoch 36/50
15825/15825 [==============================] - 8s 520us/step - loss: 0.4753 - acc: 0.8365 - val_loss: 1.0186 - val_acc: 0.7145
Epoch 37/50
15825/15825 [==============================] - 8s 518us/step - loss: 0.4574 - acc: 0.8409 - val_loss: 1.0835 - val_acc: 0.7097
Epoch 38/50
15825/15825 [==============================] - 8s 518us/step - loss: 0.4574 - acc: 0.8424 - val_loss: 1.0075 - val_acc: 0.7037
Epoch 39/50
15825/15825 [==============================] - 8s 520us/step - loss: 0.4403 - acc: 0.8490 - val_loss: 0.8989 - val_acc: 0.7324
Epoch 40/50
15825/15825 [==============================] - 8s 520us/step - loss: 0.4397 - acc: 0.8533 - val_loss: 0.9456 - val_acc: 0.7192
Epoch 41/50
15825/15825 [==============================] - 8s 516us/step - loss: 0.4290 - acc: 0.8518 - val_loss: 0.9815 - val_acc: 0.7431
Epoch 42/50
15825/15825 [==============================] - 8s 520us/step - loss: 0.4196 - acc: 0.8544 - val_loss: 0.9095 - val_acc: 0.7324
Epoch 43/50
15825/15825 [==============================] - 8s 523us/step - loss: 0.4131 - acc: 0.8587 - val_loss: 0.9477 - val_acc: 0.7455
Epoch 44/50
15825/15825 [==============================] - 8s 518us/step - loss: 0.4000 - acc: 0.8624 - val_loss: 0.9634 - val_acc: 0.7121
Epoch 45/50
15825/15825 [==============================] - 8s 519us/step - loss: 0.4122 - acc: 0.8596 - val_loss: 1.0227 - val_acc: 0.7252
Epoch 46/50
15825/15825 [==============================] - 8s 519us/step - loss: 0.3818 - acc: 0.8693 - val_loss: 1.1348 - val_acc: 0.7025
Epoch 47/50
15825/15825 [==============================] - 8s 519us/step - loss: 0.3931 - acc: 0.8662 - val_loss: 1.1801 - val_acc: 0.6977
Epoch 48/50
15825/15825 [==============================] - 8s 521us/step - loss: 0.3763 - acc: 0.8705 - val_loss: 0.9747 - val_acc: 0.7336
Epoch 49/50
15825/15825 [==============================] - 8s 521us/step - loss: 0.3812 - acc: 0.8702 - val_loss: 0.9587 - val_acc: 0.7467
Epoch 50/50
15825/15825 [==============================] - 8s 522us/step - loss: 0.3657 - acc: 0.8760 - val_loss: 1.1914 - val_acc: 0.7384
837/837 [==============================] - 0s 303us/step
Cross Validation Fold 10
Test loss: 1.1913996524530215
Test accuracy: 0.738351254551499
Summary:
Average loss: 1.4493934547075553
Average accuracy: 0.6728326352734446