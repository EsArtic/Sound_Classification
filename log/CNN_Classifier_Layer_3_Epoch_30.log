Using TensorFlow backend.
fold1 raw_shape: (873, 128, 128) (873,) aug_shape: (853, 128, 128) (853,)
fold2 raw_shape: (888, 128, 128) (888,) aug_shape: (872, 128, 128) (872,)
fold3 raw_shape: (925, 128, 128) (925,) aug_shape: (892, 128, 128) (892,)
fold4 raw_shape: (990, 128, 128) (990,) aug_shape: (1007, 128, 128) (1007,)
fold5 raw_shape: (936, 128, 128) (936,) aug_shape: (963, 128, 128) (963,)
fold6 raw_shape: (823, 128, 128) (823,) aug_shape: (819, 128, 128) (819,)
fold7 raw_shape: (838, 128, 128) (838,) aug_shape: (882, 128, 128) (882,)
fold8 raw_shape: (806, 128, 128) (806,) aug_shape: (805, 128, 128) (805,)
fold9 raw_shape: (816, 128, 128) (816,) aug_shape: (837, 128, 128) (837,)
fold10 raw_shape: (837, 128, 128) (837,) aug_shape: (790, 128, 128) (790,)
tcmalloc: large alloc 2061238272 bytes == 0x8776e000 @  0x7fd9aeccf1e7 0x7fd9ac859e51 0x7fd9ac8be8d8 0x7fd9ac8c2020 0x7fd9ac8c2595 0x7fd9ac95b3dd 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7fd9ae8ccb97 0x5afa0a
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Train on 15726 samples, validate on 873 samples
Epoch 1/30
2019-04-13 04:01:06.603305: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz
2019-04-13 04:01:06.603665: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2ae91e0 executing computations on platform Host. Devices:
2019-04-13 04:01:06.603705: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-04-13 04:01:06.789280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-04-13 04:01:06.789824: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2ae8c60 executing computations on platform CUDA. Devices:
2019-04-13 04:01:06.789878: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7
2019-04-13 04:01:06.790348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2019-04-13 04:01:06.790386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-04-13 04:01:08.274412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-04-13 04:01:08.274475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2019-04-13 04:01:08.274529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2019-04-13 04:01:08.274859: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2019-04-13 04:01:08.275103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)
2019-04-13 04:01:08.738544: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
15726/15726 [==============================] - 14s 873us/step - loss: 2.1921 - acc: 0.1534 - val_loss: 2.0619 - val_acc: 0.1833
Epoch 2/30
15726/15726 [==============================] - 8s 492us/step - loss: 2.0417 - acc: 0.2066 - val_loss: 1.8486 - val_acc: 0.3184
Epoch 3/30
15726/15726 [==============================] - 8s 492us/step - loss: 1.9063 - acc: 0.2678 - val_loss: 1.8316 - val_acc: 0.2818
Epoch 4/30
15726/15726 [==============================] - 8s 493us/step - loss: 1.8015 - acc: 0.3160 - val_loss: 1.7460 - val_acc: 0.3471
Epoch 5/30
15726/15726 [==============================] - 8s 492us/step - loss: 1.6971 - acc: 0.3516 - val_loss: 1.6553 - val_acc: 0.4032
Epoch 6/30
15726/15726 [==============================] - 8s 490us/step - loss: 1.5801 - acc: 0.4013 - val_loss: 1.5059 - val_acc: 0.4639
Epoch 7/30
15726/15726 [==============================] - 8s 490us/step - loss: 1.4653 - acc: 0.4498 - val_loss: 1.4726 - val_acc: 0.4800
Epoch 8/30
15726/15726 [==============================] - 8s 490us/step - loss: 1.3702 - acc: 0.4863 - val_loss: 1.4269 - val_acc: 0.5590
Epoch 9/30
15726/15726 [==============================] - 8s 491us/step - loss: 1.2871 - acc: 0.5187 - val_loss: 1.4041 - val_acc: 0.5281
Epoch 10/30
15726/15726 [==============================] - 8s 491us/step - loss: 1.2485 - acc: 0.5362 - val_loss: 1.3744 - val_acc: 0.5716
Epoch 11/30
15726/15726 [==============================] - 8s 489us/step - loss: 1.1830 - acc: 0.5618 - val_loss: 1.3586 - val_acc: 0.5853
Epoch 12/30
15726/15726 [==============================] - 8s 493us/step - loss: 1.1274 - acc: 0.5878 - val_loss: 1.4014 - val_acc: 0.5601
Epoch 13/30
15726/15726 [==============================] - 8s 492us/step - loss: 1.0892 - acc: 0.5989 - val_loss: 1.3767 - val_acc: 0.5934
Epoch 14/30
15726/15726 [==============================] - 8s 492us/step - loss: 1.0507 - acc: 0.6120 - val_loss: 1.3247 - val_acc: 0.6277
Epoch 15/30
15726/15726 [==============================] - 8s 488us/step - loss: 0.9960 - acc: 0.6386 - val_loss: 1.3913 - val_acc: 0.6060
Epoch 16/30
15726/15726 [==============================] - 8s 491us/step - loss: 0.9745 - acc: 0.6469 - val_loss: 1.3771 - val_acc: 0.5991
Epoch 17/30
15726/15726 [==============================] - 8s 492us/step - loss: 0.9420 - acc: 0.6581 - val_loss: 1.3471 - val_acc: 0.5808
Epoch 18/30
15726/15726 [==============================] - 8s 493us/step - loss: 0.9106 - acc: 0.6721 - val_loss: 1.4315 - val_acc: 0.5590
Epoch 19/30
15726/15726 [==============================] - 8s 492us/step - loss: 0.8653 - acc: 0.6882 - val_loss: 1.3702 - val_acc: 0.5808
Epoch 20/30
15726/15726 [==============================] - 8s 493us/step - loss: 0.8553 - acc: 0.6962 - val_loss: 1.4452 - val_acc: 0.6025
Epoch 21/30
15726/15726 [==============================] - 8s 492us/step - loss: 0.8215 - acc: 0.7053 - val_loss: 1.3671 - val_acc: 0.6094
Epoch 22/30
15726/15726 [==============================] - 8s 493us/step - loss: 0.8107 - acc: 0.7122 - val_loss: 1.3541 - val_acc: 0.6277
Epoch 23/30
15726/15726 [==============================] - 8s 492us/step - loss: 0.7805 - acc: 0.7224 - val_loss: 1.4217 - val_acc: 0.5911
Epoch 24/30
15726/15726 [==============================] - 8s 493us/step - loss: 0.7584 - acc: 0.7282 - val_loss: 1.4000 - val_acc: 0.5922
Epoch 25/30
15726/15726 [==============================] - 8s 492us/step - loss: 0.7338 - acc: 0.7415 - val_loss: 1.3445 - val_acc: 0.6392
Epoch 26/30
15726/15726 [==============================] - 8s 490us/step - loss: 0.7078 - acc: 0.7507 - val_loss: 1.3365 - val_acc: 0.6289
Epoch 27/30
15726/15726 [==============================] - 8s 491us/step - loss: 0.6798 - acc: 0.7574 - val_loss: 1.4496 - val_acc: 0.6495
Epoch 28/30
15726/15726 [==============================] - 8s 491us/step - loss: 0.6893 - acc: 0.7559 - val_loss: 1.5162 - val_acc: 0.6380
Epoch 29/30
15726/15726 [==============================] - 8s 493us/step - loss: 0.6471 - acc: 0.7712 - val_loss: 1.4340 - val_acc: 0.6186
Epoch 30/30
15726/15726 [==============================] - 8s 492us/step - loss: 0.6408 - acc: 0.7738 - val_loss: 1.4651 - val_acc: 0.6151
873/873 [==============================] - 0s 333us/step
Cross Validation Fold 1
Test loss: 1.4651426525801454
Test accuracy: 0.6151202749140894
tcmalloc: large alloc 2056781824 bytes == 0x8776e000 @  0x7fd9aeccf1e7 0x7fd9ac859e51 0x7fd9ac8be8d8 0x7fd9ac8c2020 0x7fd9ac8c2595 0x7fd9ac95b3dd 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7fd9ae8ccb97 0x5afa0a
Train on 15692 samples, validate on 888 samples
Epoch 1/30
15692/15692 [==============================] - 9s 549us/step - loss: 2.1890 - acc: 0.1432 - val_loss: 2.1600 - val_acc: 0.1104
Epoch 2/30
15692/15692 [==============================] - 8s 493us/step - loss: 2.0497 - acc: 0.2095 - val_loss: 1.9058 - val_acc: 0.2782
Epoch 3/30
15692/15692 [==============================] - 8s 493us/step - loss: 1.8906 - acc: 0.2736 - val_loss: 1.7610 - val_acc: 0.3142
Epoch 4/30
15692/15692 [==============================] - 8s 492us/step - loss: 1.7569 - acc: 0.3393 - val_loss: 1.6054 - val_acc: 0.3626
Epoch 5/30
15692/15692 [==============================] - 8s 494us/step - loss: 1.6281 - acc: 0.3915 - val_loss: 1.5810 - val_acc: 0.3761
Epoch 6/30
15692/15692 [==============================] - 8s 493us/step - loss: 1.5429 - acc: 0.4228 - val_loss: 1.4065 - val_acc: 0.4110
Epoch 7/30
15692/15692 [==============================] - 8s 493us/step - loss: 1.4357 - acc: 0.4766 - val_loss: 1.3334 - val_acc: 0.4572
Epoch 8/30
15692/15692 [==============================] - 8s 491us/step - loss: 1.3603 - acc: 0.5021 - val_loss: 1.3159 - val_acc: 0.5011
Epoch 9/30
15692/15692 [==============================] - 8s 492us/step - loss: 1.2719 - acc: 0.5333 - val_loss: 1.2101 - val_acc: 0.4989
Epoch 10/30
15692/15692 [==============================] - 8s 492us/step - loss: 1.2261 - acc: 0.5546 - val_loss: 1.2260 - val_acc: 0.5090
Epoch 11/30
15692/15692 [==============================] - 8s 493us/step - loss: 1.1814 - acc: 0.5741 - val_loss: 1.1936 - val_acc: 0.5338
Epoch 12/30
15692/15692 [==============================] - 8s 489us/step - loss: 1.1297 - acc: 0.5963 - val_loss: 1.1613 - val_acc: 0.5304
Epoch 13/30
15692/15692 [==============================] - 8s 494us/step - loss: 1.0814 - acc: 0.6099 - val_loss: 1.1560 - val_acc: 0.5653
Epoch 14/30
15692/15692 [==============================] - 8s 493us/step - loss: 1.0384 - acc: 0.6311 - val_loss: 1.1865 - val_acc: 0.5664
Epoch 15/30
15692/15692 [==============================] - 8s 493us/step - loss: 0.9804 - acc: 0.6562 - val_loss: 1.3766 - val_acc: 0.5484
Epoch 16/30
15692/15692 [==============================] - 8s 492us/step - loss: 0.9457 - acc: 0.6730 - val_loss: 1.1658 - val_acc: 0.5912
Epoch 17/30
15692/15692 [==============================] - 8s 494us/step - loss: 0.9516 - acc: 0.6665 - val_loss: 1.1399 - val_acc: 0.5428
Epoch 18/30
15692/15692 [==============================] - 8s 491us/step - loss: 0.8804 - acc: 0.6954 - val_loss: 1.2418 - val_acc: 0.5878
Epoch 19/30
15692/15692 [==============================] - 8s 489us/step - loss: 0.8735 - acc: 0.6981 - val_loss: 1.2874 - val_acc: 0.6149
Epoch 20/30
15692/15692 [==============================] - 8s 492us/step - loss: 0.8436 - acc: 0.7092 - val_loss: 1.2159 - val_acc: 0.5653
Epoch 21/30
15692/15692 [==============================] - 8s 493us/step - loss: 0.8136 - acc: 0.7207 - val_loss: 1.1989 - val_acc: 0.5743
Epoch 22/30
15692/15692 [==============================] - 8s 491us/step - loss: 0.7697 - acc: 0.7323 - val_loss: 1.2169 - val_acc: 0.5867
Epoch 23/30
15692/15692 [==============================] - 8s 491us/step - loss: 0.7628 - acc: 0.7357 - val_loss: 1.1363 - val_acc: 0.5845
Epoch 24/30
15692/15692 [==============================] - 8s 492us/step - loss: 0.7154 - acc: 0.7561 - val_loss: 1.1727 - val_acc: 0.5755
Epoch 25/30
15692/15692 [==============================] - 8s 493us/step - loss: 0.6897 - acc: 0.7648 - val_loss: 1.1562 - val_acc: 0.6160
Epoch 26/30
15692/15692 [==============================] - 8s 492us/step - loss: 0.6839 - acc: 0.7629 - val_loss: 1.2543 - val_acc: 0.6092
Epoch 27/30
15692/15692 [==============================] - 8s 493us/step - loss: 0.6659 - acc: 0.7713 - val_loss: 1.2408 - val_acc: 0.5935
Epoch 28/30
15692/15692 [==============================] - 8s 491us/step - loss: 0.6683 - acc: 0.7747 - val_loss: 1.0904 - val_acc: 0.6160
Epoch 29/30
15692/15692 [==============================] - 8s 493us/step - loss: 0.6566 - acc: 0.7727 - val_loss: 1.2778 - val_acc: 0.6104
Epoch 30/30
15692/15692 [==============================] - 8s 491us/step - loss: 0.6129 - acc: 0.7910 - val_loss: 1.1762 - val_acc: 0.6374
888/888 [==============================] - 0s 298us/step
Cross Validation Fold 2
Test loss: 1.1761875754004125
Test accuracy: 0.6373873873873874
tcmalloc: large alloc 2049310720 bytes == 0x8776e000 @  0x7fd9aeccf1e7 0x7fd9ac859e51 0x7fd9ac8be8d8 0x7fd9ac8c2020 0x7fd9ac8c2595 0x7fd9ac95b3dd 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7fd9ae8ccb97 0x5afa0a
Train on 15635 samples, validate on 925 samples
Epoch 1/30
15635/15635 [==============================] - 9s 548us/step - loss: 2.1759 - acc: 0.1535 - val_loss: 2.0612 - val_acc: 0.1838
Epoch 2/30
15635/15635 [==============================] - 8s 495us/step - loss: 1.9821 - acc: 0.2285 - val_loss: 1.9426 - val_acc: 0.2324
Epoch 3/30
15635/15635 [==============================] - 8s 496us/step - loss: 1.8595 - acc: 0.2825 - val_loss: 1.7797 - val_acc: 0.4076
Epoch 4/30
15635/15635 [==============================] - 8s 496us/step - loss: 1.7121 - acc: 0.3528 - val_loss: 1.7580 - val_acc: 0.4065
Epoch 5/30
15635/15635 [==============================] - 8s 497us/step - loss: 1.5881 - acc: 0.3971 - val_loss: 1.8251 - val_acc: 0.3957
Epoch 6/30
15635/15635 [==============================] - 8s 497us/step - loss: 1.4807 - acc: 0.4483 - val_loss: 1.5081 - val_acc: 0.4259
Epoch 7/30
15635/15635 [==============================] - 8s 497us/step - loss: 1.3756 - acc: 0.4994 - val_loss: 1.4264 - val_acc: 0.5027
Epoch 8/30
15635/15635 [==============================] - 8s 498us/step - loss: 1.2910 - acc: 0.5342 - val_loss: 1.4658 - val_acc: 0.4757
Epoch 9/30
15635/15635 [==============================] - 8s 497us/step - loss: 1.2229 - acc: 0.5678 - val_loss: 1.5056 - val_acc: 0.4335
Epoch 10/30
15635/15635 [==============================] - 8s 496us/step - loss: 1.1440 - acc: 0.5958 - val_loss: 1.6018 - val_acc: 0.5254
Epoch 11/30
15635/15635 [==============================] - 8s 496us/step - loss: 1.0899 - acc: 0.6157 - val_loss: 1.5542 - val_acc: 0.4757
Epoch 12/30
15635/15635 [==============================] - 8s 495us/step - loss: 1.0353 - acc: 0.6349 - val_loss: 1.5826 - val_acc: 0.5135
Epoch 13/30
15635/15635 [==============================] - 8s 504us/step - loss: 1.0080 - acc: 0.6480 - val_loss: 1.5880 - val_acc: 0.5373
Epoch 14/30
15635/15635 [==============================] - 8s 497us/step - loss: 0.9476 - acc: 0.6698 - val_loss: 1.5954 - val_acc: 0.5189
Epoch 15/30
15635/15635 [==============================] - 8s 497us/step - loss: 0.9278 - acc: 0.6833 - val_loss: 1.6180 - val_acc: 0.4973
Epoch 16/30
15635/15635 [==============================] - 8s 495us/step - loss: 0.8882 - acc: 0.6950 - val_loss: 1.5098 - val_acc: 0.5330
Epoch 17/30
15635/15635 [==============================] - 8s 494us/step - loss: 0.8440 - acc: 0.7064 - val_loss: 1.5456 - val_acc: 0.5351
Epoch 18/30
15635/15635 [==============================] - 8s 496us/step - loss: 0.8194 - acc: 0.7172 - val_loss: 1.4983 - val_acc: 0.5362
Epoch 19/30
15635/15635 [==============================] - 8s 495us/step - loss: 0.7851 - acc: 0.7287 - val_loss: 1.6181 - val_acc: 0.5341
Epoch 20/30
15635/15635 [==============================] - 8s 495us/step - loss: 0.7555 - acc: 0.7417 - val_loss: 1.6676 - val_acc: 0.5362
Epoch 21/30
15635/15635 [==============================] - 8s 495us/step - loss: 0.7195 - acc: 0.7580 - val_loss: 1.6249 - val_acc: 0.5416
Epoch 22/30
15635/15635 [==============================] - 8s 496us/step - loss: 0.6984 - acc: 0.7618 - val_loss: 1.7657 - val_acc: 0.5081
Epoch 23/30
15635/15635 [==============================] - 8s 492us/step - loss: 0.6794 - acc: 0.7680 - val_loss: 1.6259 - val_acc: 0.5384
Epoch 24/30
15635/15635 [==============================] - 8s 496us/step - loss: 0.6655 - acc: 0.7725 - val_loss: 1.8568 - val_acc: 0.5405
Epoch 25/30
15635/15635 [==============================] - 8s 497us/step - loss: 0.6440 - acc: 0.7809 - val_loss: 1.6194 - val_acc: 0.5351
Epoch 26/30
15635/15635 [==============================] - 8s 495us/step - loss: 0.6423 - acc: 0.7786 - val_loss: 1.5980 - val_acc: 0.5686
Epoch 27/30
15635/15635 [==============================] - 8s 496us/step - loss: 0.6051 - acc: 0.7926 - val_loss: 1.6476 - val_acc: 0.5243
Epoch 28/30
15635/15635 [==============================] - 8s 496us/step - loss: 0.5798 - acc: 0.8019 - val_loss: 1.8906 - val_acc: 0.5503
Epoch 29/30
15635/15635 [==============================] - 8s 496us/step - loss: 0.5647 - acc: 0.8055 - val_loss: 1.6905 - val_acc: 0.5643
Epoch 30/30
15635/15635 [==============================] - 8s 497us/step - loss: 0.5368 - acc: 0.8111 - val_loss: 1.9610 - val_acc: 0.5686
925/925 [==============================] - 0s 262us/step
Cross Validation Fold 3
Test loss: 1.9610024305372624
Test accuracy: 0.5686486478753991
tcmalloc: large alloc 2025717760 bytes == 0x8776e000 @  0x7fd9aeccf1e7 0x7fd9ac859e51 0x7fd9ac8be8d8 0x7fd9ac8c2020 0x7fd9ac8c2595 0x7fd9ac95b3dd 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7fd9ae8ccb97 0x5afa0a
Train on 15455 samples, validate on 990 samples
Epoch 1/30
15455/15455 [==============================] - 9s 568us/step - loss: 2.1742 - acc: 0.1452 - val_loss: 2.1423 - val_acc: 0.1657
Epoch 2/30
15455/15455 [==============================] - 8s 497us/step - loss: 2.0342 - acc: 0.2023 - val_loss: 1.9236 - val_acc: 0.2242
Epoch 3/30
15455/15455 [==============================] - 8s 497us/step - loss: 1.8312 - acc: 0.2962 - val_loss: 1.7397 - val_acc: 0.3960
Epoch 4/30
15455/15455 [==============================] - 8s 498us/step - loss: 1.6927 - acc: 0.3633 - val_loss: 1.4282 - val_acc: 0.4970
Epoch 5/30
15455/15455 [==============================] - 8s 495us/step - loss: 1.5317 - acc: 0.4289 - val_loss: 1.3350 - val_acc: 0.5000
Epoch 6/30
15455/15455 [==============================] - 8s 495us/step - loss: 1.3304 - acc: 0.5026 - val_loss: 1.2120 - val_acc: 0.5556
Epoch 7/30
15455/15455 [==============================] - 8s 498us/step - loss: 1.2301 - acc: 0.5493 - val_loss: 1.1479 - val_acc: 0.5808
Epoch 8/30
15455/15455 [==============================] - 8s 497us/step - loss: 1.1333 - acc: 0.5909 - val_loss: 1.1538 - val_acc: 0.5768
Epoch 9/30
15455/15455 [==============================] - 8s 496us/step - loss: 1.0806 - acc: 0.6086 - val_loss: 1.0423 - val_acc: 0.6020
Epoch 10/30
15455/15455 [==============================] - 8s 498us/step - loss: 0.9951 - acc: 0.6472 - val_loss: 1.0538 - val_acc: 0.6040
Epoch 11/30
15455/15455 [==============================] - 8s 497us/step - loss: 0.9169 - acc: 0.6816 - val_loss: 1.0844 - val_acc: 0.6141
Epoch 12/30
15455/15455 [==============================] - 8s 498us/step - loss: 0.8514 - acc: 0.7029 - val_loss: 1.0289 - val_acc: 0.6182
Epoch 13/30
15455/15455 [==============================] - 8s 495us/step - loss: 0.8132 - acc: 0.7147 - val_loss: 1.1013 - val_acc: 0.6131
Epoch 14/30
15455/15455 [==============================] - 8s 497us/step - loss: 0.7602 - acc: 0.7409 - val_loss: 1.0186 - val_acc: 0.6333
Epoch 15/30
15455/15455 [==============================] - 8s 496us/step - loss: 0.7087 - acc: 0.7568 - val_loss: 0.9438 - val_acc: 0.6818
Epoch 16/30
15455/15455 [==============================] - 8s 496us/step - loss: 0.6967 - acc: 0.7625 - val_loss: 0.9323 - val_acc: 0.6798
Epoch 17/30
15455/15455 [==============================] - 8s 497us/step - loss: 0.6344 - acc: 0.7870 - val_loss: 1.0923 - val_acc: 0.6495
Epoch 18/30
15455/15455 [==============================] - 8s 496us/step - loss: 0.6057 - acc: 0.7924 - val_loss: 0.9908 - val_acc: 0.6778
Epoch 19/30
15455/15455 [==============================] - 8s 496us/step - loss: 0.5791 - acc: 0.8058 - val_loss: 1.0791 - val_acc: 0.6313
Epoch 20/30
15455/15455 [==============================] - 8s 495us/step - loss: 0.5702 - acc: 0.8098 - val_loss: 0.9713 - val_acc: 0.6485
Epoch 21/30
15455/15455 [==============================] - 8s 496us/step - loss: 0.5192 - acc: 0.8254 - val_loss: 1.0627 - val_acc: 0.6434
Epoch 22/30
15455/15455 [==============================] - 8s 496us/step - loss: 0.4908 - acc: 0.8344 - val_loss: 1.0451 - val_acc: 0.6616
Epoch 23/30
15455/15455 [==============================] - 8s 496us/step - loss: 0.4697 - acc: 0.8434 - val_loss: 0.9751 - val_acc: 0.6859
Epoch 24/30
15455/15455 [==============================] - 8s 496us/step - loss: 0.4456 - acc: 0.8497 - val_loss: 0.9555 - val_acc: 0.7061
Epoch 25/30
15455/15455 [==============================] - 8s 494us/step - loss: 0.4279 - acc: 0.8591 - val_loss: 1.1313 - val_acc: 0.6646
Epoch 26/30
15455/15455 [==============================] - 8s 494us/step - loss: 0.4167 - acc: 0.8604 - val_loss: 0.9705 - val_acc: 0.6970
Epoch 27/30
15455/15455 [==============================] - 8s 493us/step - loss: 0.4278 - acc: 0.8595 - val_loss: 1.0898 - val_acc: 0.6616
Epoch 28/30
15455/15455 [==============================] - 8s 493us/step - loss: 0.3957 - acc: 0.8687 - val_loss: 0.9955 - val_acc: 0.6889
Epoch 29/30
15455/15455 [==============================] - 8s 494us/step - loss: 0.3785 - acc: 0.8731 - val_loss: 1.0802 - val_acc: 0.6768
Epoch 30/30
15455/15455 [==============================] - 8s 497us/step - loss: 0.3879 - acc: 0.8702 - val_loss: 1.0912 - val_acc: 0.6727
990/990 [==============================] - 0s 299us/step
Cross Validation Fold 4
Test loss: 1.0911732461717394
Test accuracy: 0.6727272732089264
tcmalloc: large alloc 2038562816 bytes == 0x7fd8b67e0000 @  0x7fd9aeccf1e7 0x7fd9ac859e51 0x7fd9ac8be8d8 0x7fd9ac8c2020 0x7fd9ac8c2595 0x7fd9ac95b3dd 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7fd9ae8ccb97 0x5afa0a
Train on 15553 samples, validate on 936 samples
Epoch 1/30
15553/15553 [==============================] - 9s 573us/step - loss: 2.1879 - acc: 0.1445 - val_loss: 2.1831 - val_acc: 0.1795
Epoch 2/30
15553/15553 [==============================] - 8s 497us/step - loss: 2.1038 - acc: 0.1696 - val_loss: 2.0928 - val_acc: 0.1635
Epoch 3/30
15553/15553 [==============================] - 8s 498us/step - loss: 1.9704 - acc: 0.2360 - val_loss: 1.9476 - val_acc: 0.2147
Epoch 4/30
15553/15553 [==============================] - 8s 499us/step - loss: 1.8497 - acc: 0.2895 - val_loss: 1.8718 - val_acc: 0.2233
Epoch 5/30
15553/15553 [==============================] - 8s 496us/step - loss: 1.8284 - acc: 0.3100 - val_loss: 1.8222 - val_acc: 0.2489
Epoch 6/30
15553/15553 [==============================] - 8s 499us/step - loss: 1.7226 - acc: 0.3555 - val_loss: 1.8885 - val_acc: 0.2671
Epoch 7/30
15553/15553 [==============================] - 8s 498us/step - loss: 1.6424 - acc: 0.3884 - val_loss: 1.6697 - val_acc: 0.3376
Epoch 8/30
15553/15553 [==============================] - 8s 498us/step - loss: 1.5290 - acc: 0.4292 - val_loss: 1.5625 - val_acc: 0.3622
Epoch 9/30
15553/15553 [==============================] - 8s 498us/step - loss: 1.4561 - acc: 0.4558 - val_loss: 1.4434 - val_acc: 0.4412
Epoch 10/30
15553/15553 [==============================] - 8s 499us/step - loss: 1.3680 - acc: 0.4930 - val_loss: 1.3716 - val_acc: 0.4925
Epoch 11/30
15553/15553 [==============================] - 8s 498us/step - loss: 1.2910 - acc: 0.5223 - val_loss: 1.3290 - val_acc: 0.5224
Epoch 12/30
15553/15553 [==============================] - 8s 498us/step - loss: 1.2377 - acc: 0.5454 - val_loss: 1.2333 - val_acc: 0.5524
Epoch 13/30
15553/15553 [==============================] - 8s 498us/step - loss: 1.1799 - acc: 0.5694 - val_loss: 1.1885 - val_acc: 0.5630
Epoch 14/30
15553/15553 [==============================] - 8s 499us/step - loss: 1.1197 - acc: 0.5911 - val_loss: 1.1526 - val_acc: 0.6261
Epoch 15/30
15553/15553 [==============================] - 8s 498us/step - loss: 1.0752 - acc: 0.6113 - val_loss: 1.1889 - val_acc: 0.5791
Epoch 16/30
15553/15553 [==============================] - 8s 498us/step - loss: 1.0305 - acc: 0.6284 - val_loss: 1.1473 - val_acc: 0.6079
Epoch 17/30
15553/15553 [==============================] - 8s 498us/step - loss: 0.9825 - acc: 0.6462 - val_loss: 1.1753 - val_acc: 0.5865
Epoch 18/30
15553/15553 [==============================] - 8s 498us/step - loss: 0.9475 - acc: 0.6617 - val_loss: 1.1124 - val_acc: 0.6058
Epoch 19/30
15553/15553 [==============================] - 8s 498us/step - loss: 0.8985 - acc: 0.6824 - val_loss: 1.0537 - val_acc: 0.6303
Epoch 20/30
15553/15553 [==============================] - 8s 497us/step - loss: 0.8320 - acc: 0.7004 - val_loss: 1.0265 - val_acc: 0.6442
Epoch 21/30
15553/15553 [==============================] - 8s 497us/step - loss: 0.8192 - acc: 0.7141 - val_loss: 1.0310 - val_acc: 0.6442
Epoch 22/30
15553/15553 [==============================] - 8s 497us/step - loss: 0.7635 - acc: 0.7343 - val_loss: 1.0660 - val_acc: 0.6656
Epoch 23/30
15553/15553 [==============================] - 8s 493us/step - loss: 0.7329 - acc: 0.7455 - val_loss: 1.0325 - val_acc: 0.6667
Epoch 24/30
15553/15553 [==============================] - 8s 496us/step - loss: 0.6695 - acc: 0.7705 - val_loss: 0.9763 - val_acc: 0.6784
Epoch 25/30
15553/15553 [==============================] - 8s 498us/step - loss: 0.6754 - acc: 0.7681 - val_loss: 1.0878 - val_acc: 0.6613
Epoch 26/30
15553/15553 [==============================] - 8s 497us/step - loss: 0.6461 - acc: 0.7762 - val_loss: 0.9336 - val_acc: 0.6816
Epoch 27/30
15553/15553 [==============================] - 8s 499us/step - loss: 0.6268 - acc: 0.7853 - val_loss: 0.9892 - val_acc: 0.6955
Epoch 28/30
15553/15553 [==============================] - 8s 498us/step - loss: 0.5817 - acc: 0.7995 - val_loss: 0.9235 - val_acc: 0.7019
Epoch 29/30
15553/15553 [==============================] - 8s 498us/step - loss: 0.5657 - acc: 0.8077 - val_loss: 1.0147 - val_acc: 0.7083
Epoch 30/30
15553/15553 [==============================] - 8s 498us/step - loss: 0.5409 - acc: 0.8166 - val_loss: 0.9534 - val_acc: 0.6891
936/936 [==============================] - 0s 284us/step
Cross Validation Fold 5
Test loss: 0.9534409479198293
Test accuracy: 0.6891025641025641
tcmalloc: large alloc 2072248320 bytes == 0x7fd83afa0000 @  0x7fd9aeccf1e7 0x7fd9ac859e51 0x7fd9ac8be8d8 0x7fd9ac8c2020 0x7fd9ac8c2595 0x7fd9ac95b3dd 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x506393 0x634d52 0x634e0a 0x6385c8 0x63915a 0x4a6f10 0x7fd9ae8ccb97 0x5afa0a
Train on 15810 samples, validate on 823 samples
Epoch 1/30
15810/15810 [==============================] - 9s 572us/step - loss: 2.1686 - acc: 0.1610 - val_loss: 2.0331 - val_acc: 0.1798
Epoch 2/30
15810/15810 [==============================] - 8s 497us/step - loss: 1.9832 - acc: 0.2231 - val_loss: 1.9245 - val_acc: 0.2333
Epoch 3/30
15810/15810 [==============================] - 8s 494us/step - loss: 1.8333 - acc: 0.2917 - val_loss: 1.8661 - val_acc: 0.3269
Epoch 4/30
15810/15810 [==============================] - 8s 495us/step - loss: 1.6677 - acc: 0.3626 - val_loss: 1.7670 - val_acc: 0.2977
Epoch 5/30
15810/15810 [==============================] - 8s 496us/step - loss: 1.5106 - acc: 0.4317 - val_loss: 1.6967 - val_acc: 0.4411
Epoch 6/30
15810/15810 [==============================] - 8s 495us/step - loss: 1.3387 - acc: 0.5142 - val_loss: 1.4568 - val_acc: 0.4350
Epoch 7/30
15810/15810 [==============================] - 8s 497us/step - loss: 1.2320 - acc: 0.5546 - val_loss: 1.4403 - val_acc: 0.4702
Epoch 8/30
15810/15810 [==============================] - 8s 497us/step - loss: 1.1603 - acc: 0.5873 - val_loss: 1.3638 - val_acc: 0.4702
Epoch 9/30
15810/15810 [==============================] - 8s 497us/step - loss: 1.0757 - acc: 0.6154 - val_loss: 1.4359 - val_acc: 0.4921
Epoch 10/30
15810/15810 [==============================] - 8s 497us/step - loss: 1.0257 - acc: 0.6342 - val_loss: 1.4949 - val_acc: 0.4872
Epoch 11/30
15810/15810 [==============================] - 8s 496us/step - loss: 0.9695 - acc: 0.6593 - val_loss: 1.4776 - val_acc: 0.5213
Epoch 12/30
15810/15810 [==============================] - 8s 496us/step - loss: 0.9188 - acc: 0.6732 - val_loss: 1.3805 - val_acc: 0.5128
Epoch 13/30
15810/15810 [==============================] - 8s 497us/step - loss: 0.8789 - acc: 0.6922 - val_loss: 1.3158 - val_acc: 0.5334
Epoch 14/30
15810/15810 [==============================] - 8s 495us/step - loss: 0.8905 - acc: 0.6904 - val_loss: 1.3073 - val_acc: 0.5213
Epoch 15/30
15810/15810 [==============================] - 8s 495us/step - loss: 0.8078 - acc: 0.7166 - val_loss: 1.3539 - val_acc: 0.5504
Epoch 16/30
15810/15810 [==============================] - 8s 498us/step - loss: 0.7521 - acc: 0.7395 - val_loss: 1.3741 - val_acc: 0.5298
Epoch 17/30
15810/15810 [==============================] - 8s 496us/step - loss: 0.7400 - acc: 0.7440 - val_loss: 1.4316 - val_acc: 0.5638
Epoch 18/30
15810/15810 [==============================] - 8s 496us/step - loss: 0.7016 - acc: 0.7558 - val_loss: 1.3888 - val_acc: 0.5407
Epoch 19/30
15810/15810 [==============================] - 8s 495us/step - loss: 0.6827 - acc: 0.7617 - val_loss: 1.2714 - val_acc: 0.6148
Epoch 20/30
15810/15810 [==============================] - 8s 495us/step - loss: 0.6656 - acc: 0.7705 - val_loss: 1.3474 - val_acc: 0.5857
Epoch 21/30
15810/15810 [==============================] - 8s 493us/step - loss: 0.6264 - acc: 0.7867 - val_loss: 1.3177 - val_acc: 0.6233
Epoch 22/30
15810/15810 [==============================] - 8s 495us/step - loss: 0.6163 - acc: 0.7859 - val_loss: 1.3294 - val_acc: 0.5990
Epoch 23/30
15810/15810 [==============================] - 8s 495us/step - loss: 0.5915 - acc: 0.7968 - val_loss: 1.3572 - val_acc: 0.6270
Epoch 24/30
15810/15810 [==============================] - 8s 495us/step - loss: 0.5595 - acc: 0.8082 - val_loss: 1.3476 - val_acc: 0.5881
Epoch 25/30
15810/15810 [==============================] - 8s 496us/step - loss: 0.5593 - acc: 0.8068 - val_loss: 1.3377 - val_acc: 0.6440
Epoch 26/30
15810/15810 [==============================] - 8s 497us/step - loss: 0.5594 - acc: 0.8101 - val_loss: 1.3975 - val_acc: 0.5942
Epoch 27/30
15810/15810 [==============================] - 8s 497us/step - loss: 0.5235 - acc: 0.8190 - val_loss: 1.4008 - val_acc: 0.6367
Epoch 28/30
15810/15810 [==============================] - 8s 496us/step - loss: 0.5165 - acc: 0.8251 - val_loss: 1.2936 - val_acc: 0.6160
Epoch 29/30
15810/15810 [==============================] - 8s 497us/step - loss: 0.4985 - acc: 0.8278 - val_loss: 1.3580 - val_acc: 0.6270
Epoch 30/30
15810/15810 [==============================] - 8s 496us/step - loss: 0.4953 - acc: 0.8283 - val_loss: 1.3665 - val_acc: 0.6318
823/823 [==============================] - 0s 311us/step
Cross Validation Fold 6
Test loss: 1.3665035908740752
Test accuracy: 0.6318347512734183
Train on 15732 samples, validate on 838 samples
Epoch 1/30
15732/15732 [==============================] - 9s 589us/step - loss: 2.1935 - acc: 0.1390 - val_loss: 2.1345 - val_acc: 0.1599
Epoch 2/30
15732/15732 [==============================] - 8s 497us/step - loss: 2.0625 - acc: 0.2011 - val_loss: 1.9102 - val_acc: 0.3031
Epoch 3/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.9066 - acc: 0.2714 - val_loss: 1.8790 - val_acc: 0.3604
Epoch 4/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.8048 - acc: 0.3131 - val_loss: 1.7847 - val_acc: 0.3652
Epoch 5/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.7203 - acc: 0.3525 - val_loss: 1.6413 - val_acc: 0.3998
Epoch 6/30
15732/15732 [==============================] - 8s 496us/step - loss: 1.6581 - acc: 0.3769 - val_loss: 1.6531 - val_acc: 0.3747
Epoch 7/30
15732/15732 [==============================] - 8s 494us/step - loss: 1.5594 - acc: 0.4258 - val_loss: 1.5184 - val_acc: 0.4952
Epoch 8/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.4943 - acc: 0.4467 - val_loss: 1.4574 - val_acc: 0.4988
Epoch 9/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.4205 - acc: 0.4790 - val_loss: 1.4873 - val_acc: 0.4905
Epoch 10/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.3476 - acc: 0.5061 - val_loss: 1.3544 - val_acc: 0.5155
Epoch 11/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.3005 - acc: 0.5195 - val_loss: 1.3963 - val_acc: 0.4737
Epoch 12/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.2591 - acc: 0.5388 - val_loss: 1.3398 - val_acc: 0.4761
Epoch 13/30
15732/15732 [==============================] - 8s 498us/step - loss: 1.1952 - acc: 0.5646 - val_loss: 1.2391 - val_acc: 0.6146
Epoch 14/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.1791 - acc: 0.5685 - val_loss: 1.3471 - val_acc: 0.5346
Epoch 15/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.1216 - acc: 0.5895 - val_loss: 1.2167 - val_acc: 0.6026
Epoch 16/30
15732/15732 [==============================] - 8s 496us/step - loss: 1.0805 - acc: 0.6051 - val_loss: 1.2414 - val_acc: 0.5728
Epoch 17/30
15732/15732 [==============================] - 8s 495us/step - loss: 1.0516 - acc: 0.6189 - val_loss: 1.2234 - val_acc: 0.6265
Epoch 18/30
15732/15732 [==============================] - 8s 497us/step - loss: 1.0101 - acc: 0.6368 - val_loss: 1.1632 - val_acc: 0.6372
Epoch 19/30
15732/15732 [==============================] - 8s 494us/step - loss: 0.9917 - acc: 0.6503 - val_loss: 1.1313 - val_acc: 0.6623
Epoch 20/30
15732/15732 [==============================] - 8s 496us/step - loss: 0.9585 - acc: 0.6588 - val_loss: 1.1542 - val_acc: 0.6217
Epoch 21/30
15732/15732 [==============================] - 8s 496us/step - loss: 0.9375 - acc: 0.6691 - val_loss: 1.1973 - val_acc: 0.6181
Epoch 22/30
15732/15732 [==============================] - 8s 499us/step - loss: 0.9044 - acc: 0.6821 - val_loss: 1.1291 - val_acc: 0.6337
Epoch 23/30
15732/15732 [==============================] - 8s 498us/step - loss: 0.8984 - acc: 0.6869 - val_loss: 1.0982 - val_acc: 0.6420
Epoch 24/30
15732/15732 [==============================] - 8s 497us/step - loss: 0.8661 - acc: 0.6903 - val_loss: 1.1073 - val_acc: 0.6539
Epoch 25/30
15732/15732 [==============================] - 8s 496us/step - loss: 0.8567 - acc: 0.6983 - val_loss: 1.0507 - val_acc: 0.6933
Epoch 26/30
15732/15732 [==============================] - 8s 496us/step - loss: 0.8370 - acc: 0.7084 - val_loss: 1.0752 - val_acc: 0.6754
Epoch 27/30
15732/15732 [==============================] - 8s 497us/step - loss: 0.8271 - acc: 0.7103 - val_loss: 1.0755 - val_acc: 0.6778
Epoch 28/30
15732/15732 [==============================] - 8s 497us/step - loss: 0.8097 - acc: 0.7135 - val_loss: 1.0549 - val_acc: 0.6814
Epoch 29/30
15732/15732 [==============================] - 8s 496us/step - loss: 0.7969 - acc: 0.7194 - val_loss: 1.0861 - val_acc: 0.6790
Epoch 30/30
15732/15732 [==============================] - 8s 497us/step - loss: 0.7871 - acc: 0.7232 - val_loss: 1.0822 - val_acc: 0.6635
838/838 [==============================] - 0s 287us/step
Cross Validation Fold 7
Test loss: 1.082237463577835
Test accuracy: 0.6634844870157629
Train on 15841 samples, validate on 806 samples
Epoch 1/30
15841/15841 [==============================] - 9s 583us/step - loss: 2.1804 - acc: 0.1427 - val_loss: 2.1103 - val_acc: 0.1737
Epoch 2/30
15841/15841 [==============================] - 8s 496us/step - loss: 2.1022 - acc: 0.1817 - val_loss: 1.9658 - val_acc: 0.2481
Epoch 3/30
15841/15841 [==============================] - 8s 497us/step - loss: 1.9386 - acc: 0.2521 - val_loss: 1.7538 - val_acc: 0.3350
Epoch 4/30
15841/15841 [==============================] - 8s 496us/step - loss: 1.8483 - acc: 0.2966 - val_loss: 1.6663 - val_acc: 0.4132
Epoch 5/30
15841/15841 [==============================] - 8s 494us/step - loss: 1.6878 - acc: 0.3651 - val_loss: 1.4997 - val_acc: 0.3933
Epoch 6/30
15841/15841 [==============================] - 8s 498us/step - loss: 1.5346 - acc: 0.4272 - val_loss: 1.3160 - val_acc: 0.5571
Epoch 7/30
15841/15841 [==============================] - 8s 496us/step - loss: 1.4377 - acc: 0.4688 - val_loss: 1.2657 - val_acc: 0.5484
Epoch 8/30
15841/15841 [==============================] - 8s 499us/step - loss: 1.3249 - acc: 0.5116 - val_loss: 1.2491 - val_acc: 0.5633
Epoch 9/30
15841/15841 [==============================] - 8s 497us/step - loss: 1.2612 - acc: 0.5356 - val_loss: 1.1418 - val_acc: 0.6551
Epoch 10/30
15841/15841 [==============================] - 8s 496us/step - loss: 1.2401 - acc: 0.5515 - val_loss: 1.1569 - val_acc: 0.6576
Epoch 11/30
15841/15841 [==============================] - 8s 498us/step - loss: 1.1463 - acc: 0.5875 - val_loss: 1.1081 - val_acc: 0.6452
Epoch 12/30
15841/15841 [==============================] - 8s 497us/step - loss: 1.0974 - acc: 0.6065 - val_loss: 1.1041 - val_acc: 0.6439
Epoch 13/30
15841/15841 [==============================] - 8s 497us/step - loss: 1.0662 - acc: 0.6171 - val_loss: 1.0620 - val_acc: 0.6700
Epoch 14/30
15841/15841 [==============================] - 8s 493us/step - loss: 1.0342 - acc: 0.6349 - val_loss: 1.0838 - val_acc: 0.6526
Epoch 15/30
15841/15841 [==============================] - 8s 493us/step - loss: 0.9850 - acc: 0.6590 - val_loss: 1.0433 - val_acc: 0.6749
Epoch 16/30
15841/15841 [==============================] - 8s 495us/step - loss: 0.9381 - acc: 0.6763 - val_loss: 1.0199 - val_acc: 0.6811
Epoch 17/30
15841/15841 [==============================] - 8s 495us/step - loss: 0.9103 - acc: 0.6854 - val_loss: 1.1489 - val_acc: 0.6253
Epoch 18/30
15841/15841 [==============================] - 8s 496us/step - loss: 0.8835 - acc: 0.6877 - val_loss: 0.9908 - val_acc: 0.7109
Epoch 19/30
15841/15841 [==============================] - 8s 497us/step - loss: 0.8521 - acc: 0.7031 - val_loss: 1.0382 - val_acc: 0.6811
Epoch 20/30
15841/15841 [==============================] - 8s 496us/step - loss: 0.8313 - acc: 0.7093 - val_loss: 0.9930 - val_acc: 0.6861
Epoch 21/30
15841/15841 [==============================] - 8s 500us/step - loss: 0.8084 - acc: 0.7203 - val_loss: 1.0374 - val_acc: 0.6935
Epoch 22/30
15841/15841 [==============================] - 8s 496us/step - loss: 0.7762 - acc: 0.7327 - val_loss: 1.0314 - val_acc: 0.7060
Epoch 23/30
15841/15841 [==============================] - 8s 499us/step - loss: 0.7583 - acc: 0.7373 - val_loss: 1.0397 - val_acc: 0.6923
Epoch 24/30
15841/15841 [==============================] - 8s 499us/step - loss: 0.7398 - acc: 0.7423 - val_loss: 1.0503 - val_acc: 0.7122
Epoch 25/30
15841/15841 [==============================] - 8s 501us/step - loss: 0.7194 - acc: 0.7504 - val_loss: 1.0496 - val_acc: 0.6985
Epoch 26/30
15841/15841 [==============================] - 8s 501us/step - loss: 0.6796 - acc: 0.7671 - val_loss: 1.0598 - val_acc: 0.7060
Epoch 27/30
15841/15841 [==============================] - 8s 502us/step - loss: 0.6692 - acc: 0.7702 - val_loss: 1.0400 - val_acc: 0.7159
Epoch 28/30
15841/15841 [==============================] - 8s 501us/step - loss: 0.6706 - acc: 0.7741 - val_loss: 1.1210 - val_acc: 0.6700
Epoch 29/30
15841/15841 [==============================] - 8s 498us/step - loss: 0.6247 - acc: 0.7857 - val_loss: 1.1463 - val_acc: 0.6712
Epoch 30/30
15841/15841 [==============================] - 8s 497us/step - loss: 0.6247 - acc: 0.7840 - val_loss: 1.1325 - val_acc: 0.7122
806/806 [==============================] - 0s 272us/step
Cross Validation Fold 8
Test loss: 1.1325054673557302
Test accuracy: 0.7121588089330024
Train on 15799 samples, validate on 816 samples
Epoch 1/30
15799/15799 [==============================] - 9s 582us/step - loss: 2.1800 - acc: 0.1468 - val_loss: 2.0974 - val_acc: 0.1618
Epoch 2/30
15799/15799 [==============================] - 8s 497us/step - loss: 2.1235 - acc: 0.1742 - val_loss: 1.9448 - val_acc: 0.2610
Epoch 3/30
15799/15799 [==============================] - 8s 496us/step - loss: 1.9746 - acc: 0.2546 - val_loss: 1.8262 - val_acc: 0.2463
Epoch 4/30
15799/15799 [==============================] - 8s 498us/step - loss: 1.8750 - acc: 0.2943 - val_loss: 1.7695 - val_acc: 0.2402
Epoch 5/30
15799/15799 [==============================] - 8s 497us/step - loss: 1.8694 - acc: 0.2972 - val_loss: 1.7186 - val_acc: 0.2745
Epoch 6/30
15799/15799 [==============================] - 8s 497us/step - loss: 1.8015 - acc: 0.3229 - val_loss: 1.6948 - val_acc: 0.2549
Epoch 7/30
15799/15799 [==============================] - 8s 497us/step - loss: 1.7772 - acc: 0.3332 - val_loss: 1.7412 - val_acc: 0.2672
Epoch 8/30
15799/15799 [==============================] - 8s 497us/step - loss: 1.7401 - acc: 0.3420 - val_loss: 1.6500 - val_acc: 0.2941
Epoch 9/30
15799/15799 [==============================] - 8s 497us/step - loss: 1.6955 - acc: 0.3519 - val_loss: 1.6177 - val_acc: 0.3211
Epoch 10/30
15799/15799 [==============================] - 8s 496us/step - loss: 1.6157 - acc: 0.3860 - val_loss: 1.5322 - val_acc: 0.3824
Epoch 11/30
15799/15799 [==============================] - 8s 496us/step - loss: 1.5003 - acc: 0.4379 - val_loss: 1.4183 - val_acc: 0.4375
Epoch 12/30
15799/15799 [==============================] - 8s 495us/step - loss: 1.4305 - acc: 0.4642 - val_loss: 1.3382 - val_acc: 0.4326
Epoch 13/30
15799/15799 [==============================] - 8s 496us/step - loss: 1.3524 - acc: 0.4939 - val_loss: 1.3017 - val_acc: 0.4963
Epoch 14/30
15799/15799 [==============================] - 8s 495us/step - loss: 1.3151 - acc: 0.5098 - val_loss: 1.3289 - val_acc: 0.4755
Epoch 15/30
15799/15799 [==============================] - 8s 496us/step - loss: 1.2683 - acc: 0.5259 - val_loss: 1.2776 - val_acc: 0.4914
Epoch 16/30
15799/15799 [==============================] - 8s 496us/step - loss: 1.2231 - acc: 0.5453 - val_loss: 1.2287 - val_acc: 0.5147
Epoch 17/30
15799/15799 [==============================] - 8s 495us/step - loss: 1.1703 - acc: 0.5709 - val_loss: 1.1851 - val_acc: 0.5404
Epoch 18/30
15799/15799 [==============================] - 8s 495us/step - loss: 1.1226 - acc: 0.5945 - val_loss: 1.1592 - val_acc: 0.5564
Epoch 19/30
15799/15799 [==============================] - 8s 497us/step - loss: 1.0983 - acc: 0.6103 - val_loss: 1.1038 - val_acc: 0.5662
Epoch 20/30
15799/15799 [==============================] - 8s 496us/step - loss: 1.0478 - acc: 0.6248 - val_loss: 1.0905 - val_acc: 0.5662
Epoch 21/30
15799/15799 [==============================] - 8s 497us/step - loss: 1.0252 - acc: 0.6314 - val_loss: 1.0554 - val_acc: 0.5956
Epoch 22/30
15799/15799 [==============================] - 8s 492us/step - loss: 1.0004 - acc: 0.6470 - val_loss: 1.0692 - val_acc: 0.5919
Epoch 23/30
15799/15799 [==============================] - 8s 495us/step - loss: 0.9549 - acc: 0.6618 - val_loss: 1.0768 - val_acc: 0.6042
Epoch 24/30
15799/15799 [==============================] - 8s 496us/step - loss: 0.9317 - acc: 0.6712 - val_loss: 1.0391 - val_acc: 0.6287
Epoch 25/30
15799/15799 [==============================] - 8s 497us/step - loss: 0.9195 - acc: 0.6743 - val_loss: 1.0582 - val_acc: 0.6299
Epoch 26/30
15799/15799 [==============================] - 8s 496us/step - loss: 0.9063 - acc: 0.6833 - val_loss: 1.0257 - val_acc: 0.6385
Epoch 27/30
15799/15799 [==============================] - 8s 496us/step - loss: 0.8622 - acc: 0.6956 - val_loss: 1.0496 - val_acc: 0.6189
Epoch 28/30
15799/15799 [==============================] - 8s 496us/step - loss: 0.8433 - acc: 0.6987 - val_loss: 1.0700 - val_acc: 0.6348
Epoch 29/30
15799/15799 [==============================] - 8s 496us/step - loss: 0.8180 - acc: 0.7136 - val_loss: 1.0876 - val_acc: 0.6373
Epoch 30/30
15799/15799 [==============================] - 8s 497us/step - loss: 0.8002 - acc: 0.7173 - val_loss: 1.0798 - val_acc: 0.6336
816/816 [==============================] - 0s 295us/step
Cross Validation Fold 9
Test loss: 1.079787698154356
Test accuracy: 0.633578431372549
Train on 15825 samples, validate on 837 samples
Epoch 1/30
15825/15825 [==============================] - 9s 596us/step - loss: 2.1877 - acc: 0.1431 - val_loss: 2.1070 - val_acc: 0.1661
Epoch 2/30
15825/15825 [==============================] - 8s 498us/step - loss: 2.0817 - acc: 0.1919 - val_loss: 1.9323 - val_acc: 0.2031
Epoch 3/30
15825/15825 [==============================] - 8s 500us/step - loss: 1.9224 - acc: 0.2585 - val_loss: 1.8337 - val_acc: 0.2270
Epoch 4/30
15825/15825 [==============================] - 8s 500us/step - loss: 1.8800 - acc: 0.2821 - val_loss: 1.8390 - val_acc: 0.2760
Epoch 5/30
15825/15825 [==============================] - 8s 500us/step - loss: 1.8073 - acc: 0.3078 - val_loss: 1.7582 - val_acc: 0.2760
Epoch 6/30
15825/15825 [==============================] - 8s 499us/step - loss: 1.7588 - acc: 0.3377 - val_loss: 1.7399 - val_acc: 0.2927
Epoch 7/30
15825/15825 [==============================] - 8s 499us/step - loss: 1.6570 - acc: 0.3720 - val_loss: 1.6505 - val_acc: 0.4014
Epoch 8/30
15825/15825 [==============================] - 8s 499us/step - loss: 1.5271 - acc: 0.4349 - val_loss: 1.5709 - val_acc: 0.4432
Epoch 9/30
15825/15825 [==============================] - 8s 497us/step - loss: 1.4396 - acc: 0.4701 - val_loss: 1.4806 - val_acc: 0.4946
Epoch 10/30
15825/15825 [==============================] - 8s 498us/step - loss: 1.3632 - acc: 0.4966 - val_loss: 1.4906 - val_acc: 0.4421
Epoch 11/30
15825/15825 [==============================] - 8s 497us/step - loss: 1.3106 - acc: 0.5206 - val_loss: 1.4242 - val_acc: 0.5185
Epoch 12/30
15825/15825 [==============================] - 8s 497us/step - loss: 1.2446 - acc: 0.5501 - val_loss: 1.3504 - val_acc: 0.5090
Epoch 13/30
15825/15825 [==============================] - 8s 498us/step - loss: 1.1893 - acc: 0.5714 - val_loss: 1.3089 - val_acc: 0.5090
Epoch 14/30
15825/15825 [==============================] - 8s 498us/step - loss: 1.1379 - acc: 0.5934 - val_loss: 1.2573 - val_acc: 0.5568
Epoch 15/30
15825/15825 [==============================] - 8s 497us/step - loss: 1.0798 - acc: 0.6102 - val_loss: 1.2275 - val_acc: 0.5759
Epoch 16/30
15825/15825 [==============================] - 8s 496us/step - loss: 1.0484 - acc: 0.6212 - val_loss: 1.1840 - val_acc: 0.5962
Epoch 17/30
15825/15825 [==============================] - 8s 497us/step - loss: 0.9876 - acc: 0.6475 - val_loss: 1.2043 - val_acc: 0.6225
Epoch 18/30
15825/15825 [==============================] - 8s 498us/step - loss: 0.9491 - acc: 0.6591 - val_loss: 1.0832 - val_acc: 0.6141
Epoch 19/30
15825/15825 [==============================] - 8s 496us/step - loss: 0.9046 - acc: 0.6743 - val_loss: 1.0578 - val_acc: 0.6583
Epoch 20/30
15825/15825 [==============================] - 8s 496us/step - loss: 0.8767 - acc: 0.6880 - val_loss: 1.1278 - val_acc: 0.5950
Epoch 21/30
15825/15825 [==============================] - 8s 497us/step - loss: 0.8552 - acc: 0.6931 - val_loss: 1.1116 - val_acc: 0.6320
Epoch 22/30
15825/15825 [==============================] - 8s 499us/step - loss: 0.8189 - acc: 0.7105 - val_loss: 1.1033 - val_acc: 0.6320
Epoch 23/30
15825/15825 [==============================] - 8s 497us/step - loss: 0.7841 - acc: 0.7249 - val_loss: 0.9847 - val_acc: 0.6906
Epoch 24/30
15825/15825 [==============================] - 8s 496us/step - loss: 0.7635 - acc: 0.7322 - val_loss: 1.0572 - val_acc: 0.6882
Epoch 25/30
15825/15825 [==============================] - 8s 496us/step - loss: 0.7338 - acc: 0.7410 - val_loss: 0.9910 - val_acc: 0.6941
Epoch 26/30
15825/15825 [==============================] - 8s 499us/step - loss: 0.7052 - acc: 0.7566 - val_loss: 0.9887 - val_acc: 0.6738
Epoch 27/30
15825/15825 [==============================] - 8s 497us/step - loss: 0.6837 - acc: 0.7608 - val_loss: 0.9581 - val_acc: 0.7097
Epoch 28/30
15825/15825 [==============================] - 8s 496us/step - loss: 0.6695 - acc: 0.7651 - val_loss: 1.0708 - val_acc: 0.6906
Epoch 29/30
15825/15825 [==============================] - 8s 495us/step - loss: 0.6536 - acc: 0.7719 - val_loss: 1.1243 - val_acc: 0.6392
Epoch 30/30
15825/15825 [==============================] - 8s 493us/step - loss: 0.6241 - acc: 0.7806 - val_loss: 1.0097 - val_acc: 0.7324
837/837 [==============================] - 0s 292us/step
Cross Validation Fold 10
Test loss: 1.009670777560135
Test accuracy: 0.732377538900364
Summary:
Average loss: 1.231765185013152
Average accuracy: 0.6556420164983463